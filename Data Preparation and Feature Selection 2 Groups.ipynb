{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-10-22 08:36:01.788846\n"
     ]
    }
   ],
   "source": [
    "# Load external packages\n",
    "import os\n",
    "import datetime\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter \n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, Normalizer, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, validation_curve, learning_curve, GridSearchCV, RandomizedSearchCV, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "# from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score,classification_report, auc,roc_curve, precision_recall_curve, roc_auc_score, f1_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.svm import l1_min_c, SVC\n",
    "\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTENC, SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import plot_importance\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "# # Load user-defined packages\n",
    "# os.chdir('X:/Data/Interne_studies/Kun/Machine Learning/Python packages')\n",
    "# from ConfusionMatrix import *\n",
    "\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "print(now)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\q1041308\\\\Documents\\\\Stage IQVIA\\\\Pywork'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'C:/Users/q1041308/Documents/Stage IQVIA'\n",
    "\n",
    "# Set working directory - adapt here\n",
    "os.chdir(path+'/Pywork')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\q1041308\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3057: DtypeWarning: Columns (21,22,23) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "xbt_icpc1_data = pd.read_csv(path + '/Pywork/Data Sijian 20-9-2019/xbt_comed_01_V2.csv')\n",
    "knmp1907 = pd.read_csv(path + '/Pywork/knmp_1907.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge knmp strenght value and xbt together\n",
    "xbt_icpc1_data.set_index('fcc',inplace=True)\n",
    "xbt_icpc1_data['strength_value'] = knmp1907.set_index('fcc').str_value\n",
    "xbt_icpc1_data.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform ICPC1 to Indication \n",
    "#two or three groups\n",
    "skin_diseases_dict = {\"S86\":\"Other\",\n",
    "                      \"S86.01\":\"Other\", \n",
    "                      \"S86.02\":\"Other\",\n",
    "                      \"S87\":\"AD\", \n",
    "                      \"S88\":\"Other\", \n",
    "                      \"S88.01\":\"Other\", \n",
    "                      \"S88.02\":\"Other\", \n",
    "                      \"S88.03\":\"Other\", \n",
    "                      \"S88.04\":\"Other\",\n",
    "                      \"S89\":\"Other\", \n",
    "                      \"S90\":\"Other\", \n",
    "                      \"S91\":\"Other\"} \n",
    "xbt_icpc1_data['Indication'] = xbt_icpc1_data['ICPC1'].map(skin_diseases_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select only patients from database with specific derma indications\n",
    "skin_diseases = [\"S86\", \"S86.01\", \"S86.02\", \"S87\", \"S88\", \"S88.01\", \"S88.02\", \"S88.03\", \"S88.04\", \"S89\", \"S90\", \"S91\"]\n",
    "patients_with_eczemia = xbt_icpc1_data[xbt_icpc1_data.ICPC1.isin(skin_diseases)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adapt patients with skin disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\q1041308\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\q1041308\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "#Add total amount of indication column to dataset\n",
    "#This step is used for running strong_indicator method\n",
    "num_indication =patients_with_eczemia.groupby('Indication').count().sort_values(by = 'source', ascending = False).source\n",
    "patients_with_eczemia['tot_Other'] = num_indication.loc['Other']\n",
    "patients_with_eczemia['tot_AD'] = num_indication.loc['AD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\q1041308\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:5096: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n",
      "C:\\Users\\q1041308\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "#Split Line feature into atc and medicine\n",
    "#Substitutes Line with medicine (might be better to create new feature)\n",
    "atc = []\n",
    "medicine =[]\n",
    "line_copy = patients_with_eczemia.Line.copy()\n",
    "for index in range(line_copy.shape[0]):\n",
    "    line_copy.iloc[index] = line_copy.iloc[index].split(\"_\")\n",
    "    atc.append(line_copy.iloc[index][0][0:3])\n",
    "    medicine.append( line_copy.iloc[index][1])\n",
    "\n",
    "patients_with_eczemia.Line = medicine\n",
    "patients_with_eczemia['atc'] = atc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tot_Line</th>\n",
       "      <th>AD_Line</th>\n",
       "      <th>Other_Line</th>\n",
       "      <th>dif_AD_Other</th>\n",
       "      <th>ratio_AD_Other</th>\n",
       "      <th>max_value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Line</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>METHOTREXATE</th>\n",
       "      <td>5197</td>\n",
       "      <td>131.0</td>\n",
       "      <td>5066.0</td>\n",
       "      <td>0.295389</td>\n",
       "      <td>9.866166</td>\n",
       "      <td>9.866166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CICLOSPORIN</th>\n",
       "      <td>1123</td>\n",
       "      <td>592.0</td>\n",
       "      <td>531.0</td>\n",
       "      <td>0.116106</td>\n",
       "      <td>4.369912</td>\n",
       "      <td>4.369912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KETOCONAZOLE</th>\n",
       "      <td>1086</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1064.0</td>\n",
       "      <td>0.063442</td>\n",
       "      <td>12.338815</td>\n",
       "      <td>12.338815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRIAMCINOLONE ACETONIDE</th>\n",
       "      <td>1269</td>\n",
       "      <td>382.0</td>\n",
       "      <td>887.0</td>\n",
       "      <td>0.039599</td>\n",
       "      <td>1.688050</td>\n",
       "      <td>1.688050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HYDROCORTISONE</th>\n",
       "      <td>1188</td>\n",
       "      <td>364.0</td>\n",
       "      <td>824.0</td>\n",
       "      <td>0.039109</td>\n",
       "      <td>1.731489</td>\n",
       "      <td>1.731489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>329</td>\n",
       "      <td>178.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>0.035472</td>\n",
       "      <td>4.620495</td>\n",
       "      <td>4.620495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MOMETASONE</th>\n",
       "      <td>340</td>\n",
       "      <td>156.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>0.027736</td>\n",
       "      <td>3.323168</td>\n",
       "      <td>3.323168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZATHIOPRINE</th>\n",
       "      <td>151</td>\n",
       "      <td>101.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.022442</td>\n",
       "      <td>7.917660</td>\n",
       "      <td>7.917660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FLUTICASONE</th>\n",
       "      <td>213</td>\n",
       "      <td>108.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>0.020654</td>\n",
       "      <td>4.031623</td>\n",
       "      <td>4.031623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACETYLSALICYLIC ACID</th>\n",
       "      <td>122</td>\n",
       "      <td>88.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.020174</td>\n",
       "      <td>10.144934</td>\n",
       "      <td>10.144934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BETAMETHASONE+CALCIPOTRIOL</th>\n",
       "      <td>211</td>\n",
       "      <td>1.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>0.013371</td>\n",
       "      <td>53.576434</td>\n",
       "      <td>53.576434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CLOBETASOL</th>\n",
       "      <td>736</td>\n",
       "      <td>112.0</td>\n",
       "      <td>624.0</td>\n",
       "      <td>0.012004</td>\n",
       "      <td>1.421416</td>\n",
       "      <td>1.421416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COAL TAR+MENTHOL</th>\n",
       "      <td>160</td>\n",
       "      <td>1.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>0.010062</td>\n",
       "      <td>40.565014</td>\n",
       "      <td>40.565014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DESLORATADINE</th>\n",
       "      <td>226</td>\n",
       "      <td>77.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>0.009915</td>\n",
       "      <td>2.025583</td>\n",
       "      <td>2.025583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PREDNISOLONE</th>\n",
       "      <td>93</td>\n",
       "      <td>49.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.009607</td>\n",
       "      <td>4.365047</td>\n",
       "      <td>4.365047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HYDROCORTISONE+MICONAZOLE</th>\n",
       "      <td>265</td>\n",
       "      <td>29.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>0.007937</td>\n",
       "      <td>2.076197</td>\n",
       "      <td>2.076197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OMEPRAZOLE</th>\n",
       "      <td>317</td>\n",
       "      <td>41.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>0.007481</td>\n",
       "      <td>1.717433</td>\n",
       "      <td>1.717433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FUSIDIC ACID</th>\n",
       "      <td>77</td>\n",
       "      <td>38.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.007134</td>\n",
       "      <td>3.819130</td>\n",
       "      <td>3.819130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SIMVASTATIN</th>\n",
       "      <td>79</td>\n",
       "      <td>38.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.007004</td>\n",
       "      <td>3.632831</td>\n",
       "      <td>3.632831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LEVOCETIRIZINE</th>\n",
       "      <td>129</td>\n",
       "      <td>47.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.006633</td>\n",
       "      <td>2.246619</td>\n",
       "      <td>2.246619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TACROLIMUS</th>\n",
       "      <td>77</td>\n",
       "      <td>34.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.005857</td>\n",
       "      <td>3.099245</td>\n",
       "      <td>3.099245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HYDROXYZINE</th>\n",
       "      <td>27</td>\n",
       "      <td>23.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.005590</td>\n",
       "      <td>22.537894</td>\n",
       "      <td>22.537894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DAPSONE</th>\n",
       "      <td>95</td>\n",
       "      <td>2.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>0.005526</td>\n",
       "      <td>11.863353</td>\n",
       "      <td>11.863353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HYDROCHLOROTHIAZIDE</th>\n",
       "      <td>70</td>\n",
       "      <td>31.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.005354</td>\n",
       "      <td>3.115606</td>\n",
       "      <td>3.115606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CLOBETASONE</th>\n",
       "      <td>75</td>\n",
       "      <td>31.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.005029</td>\n",
       "      <td>2.761560</td>\n",
       "      <td>2.761560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SALBUTAMOL</th>\n",
       "      <td>87</td>\n",
       "      <td>31.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.004250</td>\n",
       "      <td>2.169797</td>\n",
       "      <td>2.169797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UREA</th>\n",
       "      <td>29</td>\n",
       "      <td>19.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.004183</td>\n",
       "      <td>7.447304</td>\n",
       "      <td>7.447304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>METRONIDAZOLE</th>\n",
       "      <td>66</td>\n",
       "      <td>26.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.004017</td>\n",
       "      <td>2.547762</td>\n",
       "      <td>2.547762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACENOCOUMAROL</th>\n",
       "      <td>28</td>\n",
       "      <td>18.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.003929</td>\n",
       "      <td>7.055341</td>\n",
       "      <td>7.055341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>METOPROLOL</th>\n",
       "      <td>162</td>\n",
       "      <td>21.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>0.003808</td>\n",
       "      <td>1.712988</td>\n",
       "      <td>1.712988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FLUTICASONE+SALMETEROL</th>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DIMETINDENE</th>\n",
       "      <td>9</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SULFASALAZINE</th>\n",
       "      <td>158</td>\n",
       "      <td>NaN</td>\n",
       "      <td>158.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZOPICLONE</th>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BUMETANIDE</th>\n",
       "      <td>20</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ATENOLOL</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SALMETEROL</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PERMETHRIN</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ISOSORBIDE MONONITRATE</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ETANERCEPT</th>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>THIAMAZOLE</th>\n",
       "      <td>6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LIOTHYRONINE</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COLCHICINE</th>\n",
       "      <td>33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LEFLUNOMIDE</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ESTRIOL</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRIMETHOPRIM</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HYDROCHLOROTHIAZIDE+RAMIPRIL</th>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INSULIN ASPART</th>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FOSINOPRIL</th>\n",
       "      <td>70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DUTASTERIDE</th>\n",
       "      <td>63</td>\n",
       "      <td>NaN</td>\n",
       "      <td>63.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ALFUZOSIN</th>\n",
       "      <td>64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>64.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FENTANYL</th>\n",
       "      <td>37</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TAPENTADOL</th>\n",
       "      <td>8</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CLONAZEPAM</th>\n",
       "      <td>65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RISEDRONIC ACID</th>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LORAZEPAM</th>\n",
       "      <td>61</td>\n",
       "      <td>NaN</td>\n",
       "      <td>61.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EZETIMIBE</th>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LIDOCAINE+PRILOCAINE</th>\n",
       "      <td>12</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QUETIAPINE</th>\n",
       "      <td>10</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACITRETIN</th>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>155 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              tot_Line  AD_Line  Other_Line  dif_AD_Other  \\\n",
       "Line                                                                        \n",
       "METHOTREXATE                      5197    131.0      5066.0      0.295389   \n",
       "CICLOSPORIN                       1123    592.0       531.0      0.116106   \n",
       "KETOCONAZOLE                      1086     22.0      1064.0      0.063442   \n",
       "TRIAMCINOLONE ACETONIDE           1269    382.0       887.0      0.039599   \n",
       "HYDROCORTISONE                    1188    364.0       824.0      0.039109   \n",
       "                                   329    178.0       151.0      0.035472   \n",
       "MOMETASONE                         340    156.0       184.0      0.027736   \n",
       "AZATHIOPRINE                       151    101.0        50.0      0.022442   \n",
       "FLUTICASONE                        213    108.0       105.0      0.020654   \n",
       "ACETYLSALICYLIC ACID               122     88.0        34.0      0.020174   \n",
       "BETAMETHASONE+CALCIPOTRIOL         211      1.0       210.0      0.013371   \n",
       "CLOBETASOL                         736    112.0       624.0      0.012004   \n",
       "COAL TAR+MENTHOL                   160      1.0       159.0      0.010062   \n",
       "DESLORATADINE                      226     77.0       149.0      0.009915   \n",
       "PREDNISOLONE                        93     49.0        44.0      0.009607   \n",
       "HYDROCORTISONE+MICONAZOLE          265     29.0       236.0      0.007937   \n",
       "OMEPRAZOLE                         317     41.0       276.0      0.007481   \n",
       "FUSIDIC ACID                        77     38.0        39.0      0.007134   \n",
       "SIMVASTATIN                         79     38.0        41.0      0.007004   \n",
       "LEVOCETIRIZINE                     129     47.0        82.0      0.006633   \n",
       "TACROLIMUS                          77     34.0        43.0      0.005857   \n",
       "HYDROXYZINE                         27     23.0         4.0      0.005590   \n",
       "DAPSONE                             95      2.0        93.0      0.005526   \n",
       "HYDROCHLOROTHIAZIDE                 70     31.0        39.0      0.005354   \n",
       "CLOBETASONE                         75     31.0        44.0      0.005029   \n",
       "SALBUTAMOL                          87     31.0        56.0      0.004250   \n",
       "UREA                                29     19.0        10.0      0.004183   \n",
       "METRONIDAZOLE                       66     26.0        40.0      0.004017   \n",
       "ACENOCOUMAROL                       28     18.0        10.0      0.003929   \n",
       "METOPROLOL                         162     21.0       141.0      0.003808   \n",
       "...                                ...      ...         ...           ...   \n",
       "FLUTICASONE+SALMETEROL              32      NaN        32.0           NaN   \n",
       "DIMETINDENE                          9      9.0         NaN           NaN   \n",
       "SULFASALAZINE                      158      NaN       158.0           NaN   \n",
       "ZOPICLONE                           22      NaN        22.0           NaN   \n",
       "BUMETANIDE                          20     20.0         NaN           NaN   \n",
       "ATENOLOL                             3      NaN         3.0           NaN   \n",
       "SALMETEROL                           5      NaN         5.0           NaN   \n",
       "PERMETHRIN                           6      NaN         6.0           NaN   \n",
       "ISOSORBIDE MONONITRATE               9      NaN         9.0           NaN   \n",
       "ETANERCEPT                          10      NaN        10.0           NaN   \n",
       "THIAMAZOLE                           6      6.0         NaN           NaN   \n",
       "LIOTHYRONINE                         2      NaN         2.0           NaN   \n",
       "COLCHICINE                          33      NaN        33.0           NaN   \n",
       "LEFLUNOMIDE                         11      NaN        11.0           NaN   \n",
       "ESTRIOL                              7      NaN         7.0           NaN   \n",
       "TRIMETHOPRIM                         4      NaN         4.0           NaN   \n",
       "HYDROCHLOROTHIAZIDE+RAMIPRIL         4      4.0         NaN           NaN   \n",
       "INSULIN ASPART                       5      5.0         NaN           NaN   \n",
       "FOSINOPRIL                          70      NaN        70.0           NaN   \n",
       "DUTASTERIDE                         63      NaN        63.0           NaN   \n",
       "ALFUZOSIN                           64      NaN        64.0           NaN   \n",
       "FENTANYL                            37      NaN        37.0           NaN   \n",
       "TAPENTADOL                           8      8.0         NaN           NaN   \n",
       "CLONAZEPAM                          65      NaN        65.0           NaN   \n",
       "RISEDRONIC ACID                      3      3.0         NaN           NaN   \n",
       "LORAZEPAM                           61      NaN        61.0           NaN   \n",
       "EZETIMIBE                           13      NaN        13.0           NaN   \n",
       "LIDOCAINE+PRILOCAINE                12     12.0         NaN           NaN   \n",
       "QUETIAPINE                          10     10.0         NaN           NaN   \n",
       "ACITRETIN                           12      NaN        12.0           NaN   \n",
       "\n",
       "                              ratio_AD_Other  max_value  \n",
       "Line                                                     \n",
       "METHOTREXATE                        9.866166   9.866166  \n",
       "CICLOSPORIN                         4.369912   4.369912  \n",
       "KETOCONAZOLE                       12.338815  12.338815  \n",
       "TRIAMCINOLONE ACETONIDE             1.688050   1.688050  \n",
       "HYDROCORTISONE                      1.731489   1.731489  \n",
       "                                    4.620495   4.620495  \n",
       "MOMETASONE                          3.323168   3.323168  \n",
       "AZATHIOPRINE                        7.917660   7.917660  \n",
       "FLUTICASONE                         4.031623   4.031623  \n",
       "ACETYLSALICYLIC ACID               10.144934  10.144934  \n",
       "BETAMETHASONE+CALCIPOTRIOL         53.576434  53.576434  \n",
       "CLOBETASOL                          1.421416   1.421416  \n",
       "COAL TAR+MENTHOL                   40.565014  40.565014  \n",
       "DESLORATADINE                       2.025583   2.025583  \n",
       "PREDNISOLONE                        4.365047   4.365047  \n",
       "HYDROCORTISONE+MICONAZOLE           2.076197   2.076197  \n",
       "OMEPRAZOLE                          1.717433   1.717433  \n",
       "FUSIDIC ACID                        3.819130   3.819130  \n",
       "SIMVASTATIN                         3.632831   3.632831  \n",
       "LEVOCETIRIZINE                      2.246619   2.246619  \n",
       "TACROLIMUS                          3.099245   3.099245  \n",
       "HYDROXYZINE                        22.537894  22.537894  \n",
       "DAPSONE                            11.863353  11.863353  \n",
       "HYDROCHLOROTHIAZIDE                 3.115606   3.115606  \n",
       "CLOBETASONE                         2.761560   2.761560  \n",
       "SALBUTAMOL                          2.169797   2.169797  \n",
       "UREA                                7.447304   7.447304  \n",
       "METRONIDAZOLE                       2.547762   2.547762  \n",
       "ACENOCOUMAROL                       7.055341   7.055341  \n",
       "METOPROLOL                          1.712988   1.712988  \n",
       "...                                      ...        ...  \n",
       "FLUTICASONE+SALMETEROL                   NaN        NaN  \n",
       "DIMETINDENE                              NaN        NaN  \n",
       "SULFASALAZINE                            NaN        NaN  \n",
       "ZOPICLONE                                NaN        NaN  \n",
       "BUMETANIDE                               NaN        NaN  \n",
       "ATENOLOL                                 NaN        NaN  \n",
       "SALMETEROL                               NaN        NaN  \n",
       "PERMETHRIN                               NaN        NaN  \n",
       "ISOSORBIDE MONONITRATE                   NaN        NaN  \n",
       "ETANERCEPT                               NaN        NaN  \n",
       "THIAMAZOLE                               NaN        NaN  \n",
       "LIOTHYRONINE                             NaN        NaN  \n",
       "COLCHICINE                               NaN        NaN  \n",
       "LEFLUNOMIDE                              NaN        NaN  \n",
       "ESTRIOL                                  NaN        NaN  \n",
       "TRIMETHOPRIM                             NaN        NaN  \n",
       "HYDROCHLOROTHIAZIDE+RAMIPRIL             NaN        NaN  \n",
       "INSULIN ASPART                           NaN        NaN  \n",
       "FOSINOPRIL                               NaN        NaN  \n",
       "DUTASTERIDE                              NaN        NaN  \n",
       "ALFUZOSIN                                NaN        NaN  \n",
       "FENTANYL                                 NaN        NaN  \n",
       "TAPENTADOL                               NaN        NaN  \n",
       "CLONAZEPAM                               NaN        NaN  \n",
       "RISEDRONIC ACID                          NaN        NaN  \n",
       "LORAZEPAM                                NaN        NaN  \n",
       "EZETIMIBE                                NaN        NaN  \n",
       "LIDOCAINE+PRILOCAINE                     NaN        NaN  \n",
       "QUETIAPINE                               NaN        NaN  \n",
       "ACITRETIN                                NaN        NaN  \n",
       "\n",
       "[155 rows x 6 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Method that calculates differenting behaviour of variables between groups. \n",
    "#Input dataframe en de variabele waarvan onderscheidend vermogen moet worden uitgerekend. \n",
    "#df: dataframe\n",
    "#variable: variable for which to calculate 'differenting behaviour'\n",
    "\n",
    "def strong_indicator(df, variable):\n",
    "    #Create three columns tot_variable, AD_variable and Other_variable that \n",
    "    #contain the amount a specific value of the variable occurs in \n",
    "    #the dataset, the AD group, the Other group. \n",
    "    pat_group = df[variable].value_counts()\n",
    "    pat_per_group = df.groupby('Indication')[variable].value_counts()\n",
    "    patients_with_eczemia_copy = df.copy()\n",
    "    patients_with_eczemia_copy.set_index(variable, inplace = True)\n",
    "    patients_with_eczemia_copy['tot_' + variable] = pat_group\n",
    "    patients_with_eczemia_copy['AD_' + variable] = pat_per_group['AD']\n",
    "    patients_with_eczemia_copy['Other_' + variable] = pat_per_group['Other']\n",
    "\n",
    "    #Calculate market share of variable n_tot_sales_value / n_tot_sales\n",
    "    patients_with_eczemia_copy['perc_tot'] = patients_with_eczemia_copy['tot_' + variable] / \\\n",
    "                patients_with_eczemia_copy.loc[:,['tot_Other', 'tot_AD']].sum(axis = 1)\n",
    "    \n",
    "    #Calculate market share of variable in group n_tot_sales_value_gropu / n_tot_sales_group\n",
    "    patients_with_eczemia_copy['perc_Other']= patients_with_eczemia_copy['Other_'+variable] / \\\n",
    "                            patients_with_eczemia_copy.tot_Other\n",
    "    patients_with_eczemia_copy['perc_AD']= patients_with_eczemia_copy['AD_' + variable]/ patients_with_eczemia_copy.tot_AD\n",
    "    \n",
    "    #compute two metrics: \n",
    "    #dif_AD_Other = |perc_Other - perc_AD|\n",
    "    #ratio_AD_Other = max(perc_Other, perc_AD)/min(perc_other, per_AD)\n",
    "    patients_with_eczemia_copy['dif_AD_Other'] = np.maximum(patients_with_eczemia_copy.perc_AD, patients_with_eczemia_copy.perc_Other) \\\n",
    "                            - np.minimum(patients_with_eczemia_copy.perc_AD, patients_with_eczemia_copy.perc_Other)\n",
    "    patients_with_eczemia_copy['ratio_AD_Other'] = np.divide(\n",
    "                                                             np.maximum(patients_with_eczemia_copy.perc_AD, patients_with_eczemia_copy.perc_Other),\n",
    "                                                            np.minimum(patients_with_eczemia_copy.perc_AD, patients_with_eczemia_copy.perc_Other))\n",
    "    #create dataframe with metrics\n",
    "    grouped_dif = patients_with_eczemia_copy[[('tot_'+variable), ('AD_' + variable), ('Other_' +variable),'dif_AD_Other', 'ratio_AD_Other']].drop_duplicates()\n",
    "    grouped_dif['max_value'] = grouped_dif[['dif_AD_Other', 'ratio_AD_Other']].max(axis = 1)\n",
    "    return grouped_dif.sort_values(by ='max_value',ascending = False)\n",
    "strong_indicator(patients_with_eczemia, 'Line').sort_values(by = 'dif_AD_Other', ascending = False)\n",
    "#Look into it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['METHOTREXATE' 'CICLOSPORIN' 'KETOCONAZOLE' 'TRIAMCINOLONE ACETONIDE'\n",
      " 'HYDROCORTISONE' '' 'MOMETASONE' 'FLUTICASONE'\n",
      " 'BETAMETHASONE+CALCIPOTRIOL' 'CLOBETASOL' 'DESLORATADINE'\n",
      " 'HYDROCORTISONE+MICONAZOLE' 'OMEPRAZOLE' 'BETAMETHASONE' 'FLUCONAZOLE'\n",
      " 'MINOCYCLINE']\n",
      "['L01' 'L04' 'D07' 'D01' 'M01' 'R06' 'B01' '06P' 'D05' 'R03' 'A02' 'C07'\n",
      " 'N05' 'J02' 'J01']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cat = {}\n",
    "for variable in ['Line', 'atc']:\n",
    "    #Creer dataframe with metrics\n",
    "    df = strong_indicator(patients_with_eczemia, variable)\n",
    "    \n",
    "    #Select only values that occur more than 500 times, and take best 5 with dif_AD_other criterium.\n",
    "    #(500 is a bit arbritray but don't know how to determine a better treshold)\n",
    "    #those top 5 values will be categories\n",
    "    cat[variable] = df[df['tot_'+variable]>200].sort_values(by = 'dif_AD_Other', ascending = False).head(20).index.values\n",
    "    \n",
    "cat_line = cat['Line']\n",
    "cat_atc = cat['atc']\n",
    "print(cat_line)\n",
    "print(cat_atc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "METHOTREXATE               5197\n",
       "TRIAMCINOLONE ACETONIDE    1269\n",
       "HYDROCORTISONE             1188\n",
       "CICLOSPORIN                1123\n",
       "KETOCONAZOLE               1086\n",
       "BETAMETHASONE               938\n",
       "CLOBETASOL                  736\n",
       "MINOCYCLINE                 546\n",
       "MOMETASONE                  340\n",
       "                            329\n",
       "Name: Line, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patients_with_eczemia.Line.value_counts().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #obtain only specific molecules\n",
    "# molecules = [\"METHOTREXATE\",\"CICLOSPORIN\",\"ACITRETIN\",\"DIMETHYL FUMARATE\"]\n",
    "# patients_with_eczemia = patients_with_eczemia[patients_with_eczemia.Line.isin(molecules)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Other    15412\n",
       "AD        3932\n",
       "Name: Indication, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patients_with_eczemia.Indication.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\q1041308\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Categorize Line\n",
    "line_copy = patients_with_eczemia.Line.copy()\n",
    "for index in range(line_copy.shape[0]):\n",
    "    if line_copy.iloc[index] not in cat_line:\n",
    "        line_copy.iloc[index] = 'Other'\n",
    "\n",
    "patients_with_eczemia['Line_cat'] = line_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\q1041308\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "#Categorize atc\n",
    "line_copy = patients_with_eczemia.atc.copy()\n",
    "for index in range(line_copy.shape[0]):\n",
    "    if line_copy.iloc[index] not in cat_atc:\n",
    "        line_copy.iloc[index] = 'Other'\n",
    "\n",
    "patients_with_eczemia['atc_cat'] = line_copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\q1041308\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "#Categorize speciality\n",
    "line_copy = patients_with_eczemia.specc.copy()\n",
    "for index in range(line_copy.shape[0]):\n",
    "    if line_copy.iloc[index] not in ['Dermatoloog', 'Reumatoloog', 'Huisarts Apoth.', 'Huisarts n-apoth.']:\n",
    "        line_copy.iloc[index] = 'Other'\n",
    "    if line_copy.iloc[index] in ['Huisarts Apoth.', 'Huisarts n-apoth.']:\n",
    "        line_copy.iloc[index] = 'Huisarts'\n",
    "\n",
    "patients_with_eczemia['specc_cat'] = line_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove PsA patients (... gevallen)\n",
    "patients_with_eczemia = patients_with_eczemia[((patients_with_eczemia.specc_cat != 'Reumatoloog'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kan eruit want gebruik alleen patienten die meer dan 1 rx hebben\n",
    "# patients_with_eczemia['td_cat'] = pd.cut(patients_with_eczemia.td, 8, labels = [1,2,3,4,5,6,7,8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adapt patients with more than one rx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select all patients with more than 1 rx\n",
    "pat_duplicates = patients_with_eczemia.pat.duplicated(keep = False)\n",
    "patient_with_eczemia_more_rx = patients_with_eczemia.loc[pat_duplicates,:]\n",
    "patient_with_eczemia_more_rx.set_index('pat', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\q1041308\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\q1041308\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\Users\\q1041308\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\q1041308\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\Users\\q1041308\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:5096: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "#Create feature time going to pharmacy\n",
    "#Make group sorted by pat, that calculates the dif\n",
    "patient_with_eczemia_more_rx['numdax'] = pd.to_datetime(patient_with_eczemia_more_rx.numdax)\n",
    "group_date = patient_with_eczemia_more_rx.groupby('pat').numdax.agg(['max','min'])\n",
    "group_date['dif'] = group_date['max'] - group_date['min']\n",
    "\n",
    "#Unstack sorted group and adds is to dataset\n",
    "patient_with_eczemia_more_rx['datedif'] = group_date.unstack().dif\n",
    "\n",
    "#Makes datedif an int value\n",
    "patient_with_eczemia_more_rx['datedif'] = (patient_with_eczemia_more_rx['datedif']/np.timedelta64(1,'D')).astype('int64')\n",
    "\n",
    "#Create category (Maybe the category will be a better feature)\n",
    "patient_with_eczemia_more_rx['datedif_cat'] = pd.cut(patient_with_eczemia_more_rx.datedif, 10, labels = [1,2,3,4,5,6,7,8,9,10])\n",
    "patient_with_eczemia_more_rx.datedif = patient_with_eczemia_more_rx.datedif.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\q1041308\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\Users\\q1041308\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:8682: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n",
      "C:\\Users\\q1041308\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3325: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "C:\\Users\\q1041308\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n",
      "C:\\Users\\q1041308\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\Users\\q1041308\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:8682: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n",
      "C:\\Users\\q1041308\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3325: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "C:\\Users\\q1041308\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\q1041308\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\q1041308\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\q1041308\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "#Create Strength Per Day Feature, by summing counting units multiplying it by strength over receipts and dividing by total td. \n",
    "#Create CU Per Day Feature, by summing counting units over receipts and dividing by total td. \n",
    "#Create EU Per Day Feature, by summing euro over receipts and dividing by total td. \n",
    "\n",
    "#First impute cu/td that have zero value by median (small data leakage here) \n",
    "patient_with_eczemia_more_rx.strength_value[patient_with_eczemia_more_rx.strength_value == 0] = patient_with_eczemia_more_rx.strength_value.median()\n",
    "patient_with_eczemia_more_rx.cu[patient_with_eczemia_more_rx.cu== 0] = patient_with_eczemia_more_rx.cu.median()\n",
    "patient_with_eczemia_more_rx.td[patient_with_eczemia_more_rx.td== 0] = patient_with_eczemia_more_rx.td.median()\n",
    "patient_with_eczemia_more_rx.euro[patient_with_eczemia_more_rx.euro== 0] = patient_with_eczemia_more_rx.euro.median()\n",
    "\n",
    "pat_group = patient_with_eczemia_more_rx.reset_index().groupby('pat')['cu', 'td', 'strength_value', 'euro'].sum()\n",
    "pat_group['strength_per_day']= pat_group.cu*pat_group.strength_value/pat_group.td\n",
    "pat_group['cu_per_day']= pat_group.cu/pat_group.td\n",
    "pat_group['eu_per_day'] = pat_group.euro/pat_group.td\n",
    "\n",
    "patient_with_eczemia_more_rx['strength_per_day'] = pat_group.cu_per_day\n",
    "patient_with_eczemia_more_rx['cu_per_day'] = pat_group.cu_per_day\n",
    "patient_with_eczemia_more_rx['eu_per_day'] = pat_group.eu_per_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creer voor de variabelen Line_cat, atc_cat en specc_cat kolommen waarin staat hoevaak een feature gebruikt wordt.\n",
    "def create_col_value(col, df):\n",
    "    pivot = pd.pivot_table(df.reset_index(), index = 'pat', columns = col, values = 'fcc', aggfunc= 'count', margins = True )\n",
    "    pivot_perc = pivot / pivot.loc[:, 'All'][:,None]\n",
    "    return df.join(pivot_perc.iloc[:-1,:-1].fillna(0), lsuffix = col)\n",
    "\n",
    "patient_with_eczemia_more_rx = create_col_value('Line_cat', patient_with_eczemia_more_rx)\n",
    "patient_with_eczemia_more_rx = create_col_value('atc_cat', patient_with_eczemia_more_rx)\n",
    "patient_with_eczemia_more_rx = create_col_value('specc_cat', patient_with_eczemia_more_rx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creeer variabelen met aantal verschillende medicijnen, med_mode, specc_mode en atc_mode\n",
    "pat_group['unique_med'] = patient_with_eczemia_more_rx.reset_index().groupby('pat').Line.unique()\n",
    "pat_group['med_mode'] = patient_with_eczemia_more_rx.reset_index().groupby('pat').Line_cat.agg(pd.Series.mode)\n",
    "pat_group['specc_cat_mode'] = patient_with_eczemia_more_rx.reset_index().groupby('pat').specc_cat.agg(pd.Series.mode)\n",
    "pat_group['num_med'] = pat_group.unique_med.apply(lambda x: len(x))\n",
    "pat_group['Indication'] = patient_with_eczemia_more_rx.reset_index().groupby('pat').Indication.unique()\n",
    "pat_group['double'] = pat_group.Indication.apply(lambda x: len(x) > 1 and 'AD' in x) \n",
    "pat_group['atc_mode'] = patient_with_eczemia_more_rx.reset_index().groupby('pat').atc_cat.agg(pd.Series.mode)\n",
    "patient_with_eczemia_more_rx['num_med'] = pat_group.num_med\n",
    "patient_with_eczemia_more_rx['med_mode'] = pat_group.med_mode\n",
    "patient_with_eczemia_more_rx['specc_mode'] = pat_group.specc_cat_mode\n",
    "patient_with_eczemia_more_rx['atc_mode'] = pat_group.atc_mode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(pat_group.double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create from more rx a single line patient\n",
    "#Kies de patienten met de laatste afhaaldatum. Door het gebruiken van mode etc is de info over vorige aankopen ook bij die line inbegrepen.\n",
    "#Ik kies hiermee patient met 1 disease. Terwijl ze meerdere diseasen kunnen hebben\n",
    "pat_single_line = patient_with_eczemia_more_rx.reset_index().loc[patient_with_eczemia_more_rx.reset_index().groupby('pat').numdax.idxmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "def refactor_mode(variable, df):\n",
    "    pat_single_line = df\n",
    "    line_copy = []\n",
    "    line_copy = pat_single_line[variable].copy()\n",
    "    for index,val in enumerate(line_copy):\n",
    "        if(type(line_copy.iloc[index]) == np.ndarray):\n",
    "            line_copy.iloc[index] = line_copy.iloc[index][0]+line_copy.iloc[index][1]  #Hiermee wordt de medication gereduceerd tot ofwel 2 letters of twee woorden\n",
    "        pat_single_line[variable] = pd.Series(line_copy)\n",
    "    return pat_single_line\n",
    "\n",
    "pat_single_line = refactor_mode('med_mode', pat_single_line)\n",
    "pat_single_line = refactor_mode('specc_mode', pat_single_line)\n",
    "pat_single_line = refactor_mode('atc_mode', pat_single_line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop certain elements From data\n",
    "    #Hier is dan de data per patient\n",
    "    #Ofwel datedif ofwel datedif_cat. Als MC geen probleem is maakt dat niet uit.\n",
    "#     pat_single_line = pat_single_line[['Indication', 'datedif', 'cu_per_day', 'num_med', 'med_mode', 'specc_mode', 'sex', 'age', 'atc_mode']]\n",
    "    \n",
    "def drop_variables(drop_elements, df):\n",
    "    df_new = df.drop(drop_elements,axis = 1)\n",
    "    return df_new\n",
    "\n",
    "#Pat single line\n",
    "# ['pat', 'source', 'fcc', 'numdax', 'zhagb_WNRx', 'specn', 'specc',\n",
    "#        'arts', 'sex', 'Line', 'pack_info', 'phdb', 'rxnr', 'datamonth', 'cu',\n",
    "#        'td', 'euro', 'brflag', 'maand', 'sub', 'Tar', 'AWBZ', 'ICPC1', 'ZIC',\n",
    "#        'uzovi', 'zhagb', 'type_data', 'age', 'PKA', 'ever_F13', 'Indication',\n",
    "#        'tot_Other', 'tot_AD', 'tot_PsO', 'atc', 'Line_cat', 'atc_cat',\n",
    "#        'specc_cat', 'td_cat', 'datedif', 'datedif_cat', 'cu_per_day',\n",
    "#        'CICLOSPORIN', 'HYDROCORTISONE', 'KETOCONAZOLE', 'METHOTREXATE',\n",
    "#        'Otheratc_cat', 'TRIAMCINOLONE ACETONIDE', 'D01', 'D07', 'L01', 'L04',\n",
    "#        'M01', 'Otherspecc_cat', 'Dermatoloog', 'Huisarts', 'Other', 'num_med',\n",
    "#        'med_mode', 'specc_mode', 'atc_mode']\n",
    "#Pat eczemia \n",
    "# ['source', 'pat', 'fcc', 'numdax', 'zhagb_WNRx', 'specn', 'specc',\n",
    "#        'arts', 'sex', 'Line', 'pack_info', 'phdb', 'rxnr', 'datamonth', 'cu',\n",
    "#        'td', 'euro', 'brflag', 'maand', 'sub', 'Tar', 'AWBZ', 'ICPC1', 'ZIC',\n",
    "#        'uzovi', 'zhagb', 'type_data', 'age', 'PKA', 'ever_F13', 'Indication',\n",
    "#        'tot_Other', 'tot_AD', 'tot_PsO', 'atc', 'Line_cat', 'atc_cat',\n",
    "#        'specc_cat', 'td_cat']\n",
    "\n",
    "#Droppen van variabelen Geen idee of multicollineariteit groot probleem is.\\\n",
    "    #Houd geen rekening met collineariteit, voor patient per line\n",
    "# drop_elements_per_pat = ['pat', 'source', 'fcc', 'numdax', 'zhagb_WNRx', 'specn', 'specc','arts', 'Line', 'pack_info', 'phdb', 'rxnr',\n",
    "#                      'datamonth', 'cu','td', 'euro', 'brflag', 'maand', 'sub', 'Tar', 'AWBZ', 'ICPC1', 'ZIC', 'uzovi', 'zhagb',\n",
    "#                      'type_data', 'PKA', 'ever_F13','atc','tot_Other', 'tot_AD', 'tot_PsO', 'specc_cat', 'Line_cat', 'atc_cat', 'td_cat']\n",
    "# drop_elements_per_pat_account_mc_datedifcat = ['pat', 'source', 'fcc', 'numdax', 'zhagb_WNRx', 'specn', 'specc',\n",
    "#        'arts','Line', 'pack_info', 'phdb', 'rxnr', 'datamonth', 'cu',\n",
    "#        'td', 'euro', 'brflag', 'maand', 'sub', 'Tar', 'AWBZ', 'ICPC1', 'ZIC',\n",
    "#        'uzovi', 'zhagb', 'type_data','PKA', 'ever_F13', \n",
    "#        'Line_cat', 'atc_cat', 'specc_cat', 'td_cat', \n",
    "#                                     'datedif', 'tot_Other', 'tot_AD', 'tot_PsO',\n",
    "                                    \n",
    "#        'atc']\n",
    "# drop_elements_per_pat_account_mc_datedif = ['pat', 'source', 'fcc', 'numdax', 'zhagb_WNRx', 'specn', 'specc',\n",
    "#        'arts','Line', 'pack_info', 'phdb', 'rxnr', 'datamonth', 'cu',\n",
    "#        'td', 'euro', 'brflag', 'maand', 'sub', 'Tar', 'AWBZ', 'ICPC1', 'ZIC',\n",
    "#        'uzovi', 'zhagb', 'type_data','PKA', 'ever_F13', \n",
    "#        'Line_cat', 'atc_cat', 'specc_cat', 'td_cat', \n",
    "#        'datedif_cat', 'tot_Other', 'tot_AD', 'tot_PsO',                      \n",
    "#        'atc']\n",
    "# #Houd geen rekening met collineariteit, voor patient\n",
    "# drop_elements_normal = ['source',  'fcc', 'numdax', 'zhagb_WNRx', 'specn', 'specc',\n",
    "#        'arts', 'Line', 'pack_info', 'datamonth', 'cu',\n",
    "#        'td', 'euro', 'brflag', 'maand', 'Tar', 'AWBZ', 'ICPC1', 'ZIC',\n",
    "#        'uzovi', 'zhagb', 'type_data', 'PKA', 'ever_F13',\n",
    "#        'tot_Other', 'tot_AD', 'tot_PsO', 'atc']\n",
    "# drop_elements_normal_keep_much = ['source', 'numdax', 'zhagb_WNRx',\n",
    "#        'phdb', 'datamonth', 'brflag', 'maand', 'ICPC1', 'PKA', 'ever_F13', \n",
    "#         'tot_Other', 'tot_AD', 'tot_PsO', 'ZIC','specn', 'AWBZ']\n",
    "# drop_elements_mc = ['source',  'fcc', 'numdax', 'zhagb_WNRx', 'specn', 'specc',\n",
    "#        'arts', 'Line', 'pack_info', 'phdb', 'rxnr', 'datamonth',\n",
    "#        'td', 'brflag', 'maand', 'sub', 'Tar', 'AWBZ', 'ICPC1', 'ZIC',\n",
    "#        'uzovi', 'zhagb', 'type_data', 'PKA', 'ever_F13', \n",
    "#        'tot_Other', 'tot_AD', 'tot_PsO', 'atc']\n",
    "\n",
    "#Droppen van variabelen Bij slechts 2 groepen Geen idee of multicollineariteit groot probleem is.\\\n",
    "    #Houd geen rekening met collineariteit, voor patient per line\n",
    "drop_elements_per_pat = ['pat', 'source', 'fcc', 'numdax', 'zhagb_WNRx', 'specn', 'specc','arts', 'Line', 'pack_info', 'phdb', 'rxnr',\n",
    "                     'datamonth', 'cu','td', 'euro', 'brflag', 'maand', 'sub', 'Tar', 'AWBZ', 'ICPC1', 'ZIC', 'uzovi', 'zhagb',\n",
    "                     'type_data', 'PKA', 'ever_F13','atc', 'specc_cat', 'Line_cat', 'atc_cat',  'tot_Other', 'tot_AD']\n",
    "drop_elements_per_pat_account_mc_datedifcat = ['pat', 'source', 'fcc', 'numdax', 'zhagb_WNRx', 'specn', 'specc',\n",
    "       'arts','Line', 'pack_info', 'phdb', 'rxnr', 'datamonth', 'cu',\n",
    "       'td', 'euro', 'brflag', 'maand', 'sub', 'Tar', 'AWBZ', 'ICPC1', 'ZIC',\n",
    "       'uzovi', 'zhagb', 'type_data','PKA', 'ever_F13', \n",
    "       'Line_cat', 'atc_cat', 'specc_cat', \n",
    "                                    'datedif',                                   \n",
    "       'atc', 'tot_Other', 'tot_AD']\n",
    "drop_elements_per_pat_account_mc_datedif = ['pat', 'source', 'fcc', 'numdax', 'zhagb_WNRx', 'specn', 'specc',\n",
    "       'arts','Line', 'pack_info', 'phdb', 'rxnr', 'datamonth', 'cu',\n",
    "       'td', 'euro', 'brflag', 'maand', 'sub', 'Tar', 'AWBZ', 'ICPC1', 'ZIC',\n",
    "       'uzovi', 'zhagb', 'type_data','PKA', 'ever_F13', \n",
    "       'Line_cat', 'atc_cat', 'specc_cat', \n",
    "       'datedif_cat', 'atc', 'tot_Other', 'tot_AD', 'strength_value']\n",
    "\n",
    "\n",
    "pat_single_mc_datedif = drop_variables(drop_elements_per_pat_account_mc_datedif, pat_single_line)\n",
    "pat_single_mc_datedifcat = drop_variables(drop_elements_per_pat_account_mc_datedifcat, pat_single_line)\n",
    "pat_single_normal = drop_variables(drop_elements_per_pat, pat_single_line)\n",
    "# patients_with_eczemia_normal = drop_variables(drop_elements_normal, patients_with_eczemia)\n",
    "# patients_with_eczemia_keep_much = drop_variables(drop_elements_normal_keep_much, patients_with_eczemia)\n",
    "# patients_with_eczemia_mc = drop_variables(drop_elements_mc, patients_with_eczemia)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['sex', 'age', 'Indication', 'datedif', 'strength_per_day', 'cu_per_day',\n",
      "       'eu_per_day', '', 'BETAMETHASONE', 'BETAMETHASONE+CALCIPOTRIOL',\n",
      "       'CICLOSPORIN', 'CLOBETASOL', 'DESLORATADINE', 'FLUCONAZOLE',\n",
      "       'FLUTICASONE', 'HYDROCORTISONE', 'HYDROCORTISONE+MICONAZOLE',\n",
      "       'KETOCONAZOLE', 'METHOTREXATE', 'MINOCYCLINE', 'MOMETASONE',\n",
      "       'OMEPRAZOLE', 'Otheratc_cat', 'TRIAMCINOLONE ACETONIDE', '06P', 'A02',\n",
      "       'B01', 'C07', 'D01', 'D05', 'D07', 'J01', 'J02', 'L01', 'L04', 'M01',\n",
      "       'N05', 'Otherspecc_cat', 'R03', 'R06', 'Dermatoloog', 'Huisarts',\n",
      "       'Other', 'num_med', 'med_mode', 'specc_mode', 'atc_mode'],\n",
      "      dtype='object')\n",
      "Index(['sex', 'age', 'strength_value', 'Indication', 'datedif_cat',\n",
      "       'strength_per_day', 'cu_per_day', 'eu_per_day', '', 'BETAMETHASONE',\n",
      "       'BETAMETHASONE+CALCIPOTRIOL', 'CICLOSPORIN', 'CLOBETASOL',\n",
      "       'DESLORATADINE', 'FLUCONAZOLE', 'FLUTICASONE', 'HYDROCORTISONE',\n",
      "       'HYDROCORTISONE+MICONAZOLE', 'KETOCONAZOLE', 'METHOTREXATE',\n",
      "       'MINOCYCLINE', 'MOMETASONE', 'OMEPRAZOLE', 'Otheratc_cat',\n",
      "       'TRIAMCINOLONE ACETONIDE', '06P', 'A02', 'B01', 'C07', 'D01', 'D05',\n",
      "       'D07', 'J01', 'J02', 'L01', 'L04', 'M01', 'N05', 'Otherspecc_cat',\n",
      "       'R03', 'R06', 'Dermatoloog', 'Huisarts', 'Other', 'num_med', 'med_mode',\n",
      "       'specc_mode', 'atc_mode'],\n",
      "      dtype='object')\n",
      "Index(['sex', 'age', 'strength_value', 'Indication', 'datedif', 'datedif_cat',\n",
      "       'strength_per_day', 'cu_per_day', 'eu_per_day', '', 'BETAMETHASONE',\n",
      "       'BETAMETHASONE+CALCIPOTRIOL', 'CICLOSPORIN', 'CLOBETASOL',\n",
      "       'DESLORATADINE', 'FLUCONAZOLE', 'FLUTICASONE', 'HYDROCORTISONE',\n",
      "       'HYDROCORTISONE+MICONAZOLE', 'KETOCONAZOLE', 'METHOTREXATE',\n",
      "       'MINOCYCLINE', 'MOMETASONE', 'OMEPRAZOLE', 'Otheratc_cat',\n",
      "       'TRIAMCINOLONE ACETONIDE', '06P', 'A02', 'B01', 'C07', 'D01', 'D05',\n",
      "       'D07', 'J01', 'J02', 'L01', 'L04', 'M01', 'N05', 'Otherspecc_cat',\n",
      "       'R03', 'R06', 'Dermatoloog', 'Huisarts', 'Other', 'num_med', 'med_mode',\n",
      "       'specc_mode', 'atc_mode'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(pat_single_mc_datedif.columns)\n",
    "print(pat_single_mc_datedifcat.columns)\n",
    "print(pat_single_normal.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Make Categorical Data\n",
    "\n",
    "# #Data per line\n",
    "# #     categorical_columns_unordered = ['sex', 'med_mode', 'Indication', 'specc_mode','atc_mode']\n",
    "# #     #Jaspers way\n",
    "# categorical_columns_unordered = ['sex', 'Indication', 'med_mode', 'specc_mode', 'atc_mode', 'Line_cat', 'atc_cat', 'specc_cat']\n",
    "# for col in categorical_columns_unordered:\n",
    "#     pat_single_line.loc[:,col] = pd.Categorical(pat_single_line.loc[:,col], ordered = False)\n",
    "# categorical_columns_unordered.remove('Indication')\n",
    "\n",
    "# #Data per line\n",
    "# categorical_columns_unordered = ['sex', 'Line_cat', 'Tar', 'specc_cat', 'Indication', 'atc_cat']\n",
    "# for col in categorical_columns_unordered:\n",
    "#     patients_with_eczemia[col] = pd.Categorical(patients_with_eczemia[col], ordered = False)\n",
    "# categorical_columns_unordered.remove('Indication')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\") # do not print warnings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Y and X and dummies..remove('Indication'\n",
    "# for\n",
    "# if(per_patient):\n",
    "#     X = pd.get_dummies(pat_single_line.drop('Indication', axis = 1), columns = categorical_columns_unordered, drop_first=True, dtype = 'int')\n",
    "# #     X.datedif = X.datedif.astype('int64') #If per person and we use datedif instead of datecat\n",
    "#     X.datedif_cat = X.datedif_cat.astype('int')\n",
    "#     y = pat_single_line.Indication\n",
    "# else:\n",
    "#     X = pd.get_dummies(patients_with_eczemia.drop('Indication', axis = 1), columns = categorical_columns_unordered, drop_first=True, dtype = 'int')\n",
    "#     X.td_cat = X.td_cat.astype('int64') #If per line use this #PerLine\n",
    "#     y = patients_with_eczemia.Indication\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ros = RandomOverSampler(random_state=42)\n",
    "# X_ros, y_ros = ros.fit_resample(X_train, y_train)\n",
    "# X_ros = pd.DataFrame(X_ros)\n",
    "# X_ros.columns = X_train.columns\n",
    "# y_ros = pd.Series(y_ros)\n",
    "\n",
    "# #Anders moet alles veranderen. \n",
    "# X_train = X_ros\n",
    "# y_train = y_ros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot learning curve\n",
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n",
    "                        n_jobs=1, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt\n",
    "\n",
    "# Plot validation curve\n",
    "def plot_validation_curve(estimator, title, X, y, param_name, param_range, ylim=None, cv=None,\n",
    "                        n_jobs=1, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    train_scores, test_scores = validation_curve(estimator, X, y, param_name, param_range, cv)\n",
    "    train_mean = np.mean(train_scores, axis=1)\n",
    "    train_std = np.std(train_scores, axis=1)\n",
    "    test_mean = np.mean(test_scores, axis=1)\n",
    "    test_std = np.std(test_scores, axis=1)\n",
    "    plt.plot(param_range, train_mean, color='r', marker='o', markersize=5, label='Training score')\n",
    "    plt.fill_between(param_range, train_mean + train_std, train_mean - train_std, alpha=0.15, color='r')\n",
    "    plt.plot(param_range, test_mean, color='g', linestyle='--', marker='s', markersize=5, label='Validation score')\n",
    "    plt.fill_between(param_range, test_mean + test_std, test_mean - test_std, alpha=0.15, color='g')\n",
    "    plt.grid() \n",
    "    plt.xscale('log')\n",
    "    plt.legend(loc='best') \n",
    "    plt.xlabel('Parameter') \n",
    "    plt.ylabel('Score') \n",
    "    plt.ylim(ylim)\n",
    "    plt.title(title)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## Logreg Base Case"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Not very good results with feature selection of Cheng, iig "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Bedoeld om meerdere patienten terug te leiden naar 1 ding. Somehow zijn de patinenten niet gelijk dus werkt niet echt.\n",
    "def compare_pat_predictions(actual_pat, pred):\n",
    "    df = actual_pat\n",
    "    df['pred'] = pred\n",
    "    mode_actual = df.reset_index().groupby('pat').Indication.agg(pd.Series.mode)\n",
    "    mode_predictions = df.reset_index().groupby('pat').pred.agg(pd.Series.mode)\n",
    "    return (classification_report(mode_actual,mode_predictions, target_names=['AD', 'Other', 'PsO']))\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#### Load Data\n",
    "pat_single_normal = pd.read_csv(path + '/Pywork/FeatureSelectionCCheng/data4modeling.csv')\n",
    "\n",
    "#Change y column\n",
    "indications = {\"PsO\": 'Other', 'AD': 'AD', 'Others': 'Other'} \n",
    "pat_single_normal['Indication'] = pat_single_normal['indication'].map(indications)\n",
    "pat_single_normal =  pat_single_normal.drop('indication', axis = 1)\n",
    "pat_single_normal.dropna(axis = 1, inplace = True)\n",
    "\n",
    " #Find object columns and make these categorical (not waterproof, numeric columns might be categorical as well)\n",
    "categorical_columns_unordered = pat_single_normal.select_dtypes(include = object).columns\n",
    "for col in categorical_columns_unordered:\n",
    "    pat_single_normal.loc[:,col] = pd.Categorical(pat_single_normal.loc[:,col], ordered = False)\n",
    "#run base case\n",
    "scores_file = open('C:/Users/q1041308/Documents/Stage IQVIA/Scores/1000_features_try.txt', 'w')\n",
    "score_dict = {}\n",
    "classifier_method(pat_single_normal, 'Data', RandomForestClassifier(random_state=42), 'LogReg', scores_file, 1, True, score_dict)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Create table for missing data analysis\n",
    "def draw_missing_data_table(df):\n",
    "    total = df.isnull().sum().sort_values(ascending=False)\n",
    "    percent = (df.isnull().sum()/df.isnull().count()).sort_values(ascending=False)\n",
    "    missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "    return missing_data\n",
    "draw_missing_data_table(xbt_icpc1_data).head(5)\n",
    "# xbt_icpc1_data\n",
    "# sum(xbt_icpc1_data.groupby('pat').Indication.value_counts() > 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Dinsdag ontdekt dat er grote fout in zat qua methodologie. \n",
    "#Base case model for running different datasets\n",
    "#df = dataframe\n",
    "#df_name = dataframe name\n",
    "#clf = classifier\n",
    "#clf_name = classifer name\n",
    "#scores_file = file to which output is writen\n",
    "#sample_strat, whether to oversample or not. sample_strat = 0, normal, sample_strat = 1, oversample sample strat = 2 undersapmle\n",
    "#Include_confusion = boolean, whether or not to include confusion in scores_file\n",
    "#score_dict = Dictionary in which to save scores\n",
    "def classifier_method(df, df_name, clf, clf_name, scores_file, sample_strat, include_confusion, score_dict):\n",
    "    score_string = df_name + \": \" + clf_name+ \" \"\n",
    "    \n",
    "    y = df[['Indication']]\n",
    "    #map AD and Other to 1 and 0 for convenience\n",
    "    bin_map = {'AD': 1, 'Other': 0}\n",
    "    y.Indication = y.Indication.map(bin_map)\n",
    "\n",
    "    X = (df.drop(['Indication'], axis = 1))\n",
    "    columns = X.columns\n",
    "    data_types = X.dtypes\n",
    "    \n",
    "    #eigenlijk wil ik dit van tevoren doen.\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "    \n",
    "    #Zorg voor index lopend van 1 tot n -> voor splitting dataset manually\n",
    "    X_train.reset_index(inplace = True,drop = True)\n",
    "    y_train.reset_index(inplace = True, drop = True)\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits = 3, random_state = 42)\n",
    "    skf.get_n_splits(X_train, y_train)\n",
    "    \n",
    "    scores = []\n",
    "    scores_acc = []\n",
    "    scores_auc = []\n",
    "    for train_index, test_index in skf.split(X_train, y_train):\n",
    "        \n",
    "        #Manually split test data into train and test (before over/undersampling) \n",
    "        #Also this code could probably be reduced to 3 lines using imblearn Pipeline\n",
    "        X_train_split, X_test_split = X_train.loc[train_index], X_train.loc[test_index]\n",
    "        y_train_split, y_test_split = y_train.loc[train_index], y_train.loc[test_index]\n",
    "        \n",
    "        #Oversampling\n",
    "        if(sample_strat == 1):\n",
    "            score_string = score_string + 'Oversample: '\n",
    "            #Since there are categorical variables and smote cannot deal with it use SMOTE NC. \n",
    "            #In this step I determine the columns that are categorical. \n",
    "            cat_col_index = [X_train_split.columns.get_loc(c) for c in X_train_split.select_dtypes(include = 'category').columns if c in X_train_split]\n",
    "            smote_nc = SMOTENC(categorical_features=cat_col_index, random_state=42)\n",
    "            \n",
    "            #SMOTE resample xtrainpslit and ytrainsplit\n",
    "            X_train_split, y_train_split = smote_nc.fit_resample(X_train_split, y_train_split)\n",
    "            \n",
    "            #Create good df (Smote fucks it up)\n",
    "            X_train_split = pd.DataFrame(X_train_split)\n",
    "            X_train_split.columns = columns\n",
    "            X_train_split = X_train_split.astype(data_types)\n",
    "            y_train_split = pd.Series(y_train_split)\n",
    "        \n",
    "        #Undersampling\n",
    "        if(sample_strat == 2):\n",
    "            score_string = score_string + 'Undersample: '\n",
    "            \n",
    "            #Manually undersampling by selecting no_AD patients out all indices. \n",
    "            no_AD = len(y_train_split[y_train_split.Indication == 1])\n",
    "            Other_indices = y_train_split[y_train_split.Indication== 0].index\n",
    "            random_indices = np.random.choice(Other_indices, no_AD, replace = True)\n",
    "            AD_indices = y_train_split[y_train_split.Indication == 1].index\n",
    "            \n",
    "            #This are all indices (as many AD indices as Other indices)\n",
    "            under_sample_indices = np.concatenate([random_indices, AD_indices])\n",
    "            \n",
    "            #Undersample with under_sample_indices \n",
    "            y_train_split = y_train_split.loc[under_sample_indices]\n",
    "            X_train_split = X_train_split.loc[under_sample_indices]\n",
    "        \n",
    "        #Get dummies\n",
    "        X_train_split = pd.get_dummies(X_train_split)\n",
    "        X_test_split = pd.get_dummies(X_test_split)\n",
    "           \n",
    "        random_state = 42\n",
    "\n",
    "        ## Base Case Model\n",
    "        clf.fit(X_train_split, y_train_split)\n",
    "        \n",
    "        y_predict = clf.predict(X_test_split)\n",
    "        scores.append(f1_score(y_test_split, y_predict))\n",
    "        scores_acc.append(accuracy_score(y_test_split, y_predict))\n",
    "\n",
    "        #Add some funky auc precision recall curve\n",
    "        no_skill_probs = [0 for _ in range(len(y_test_split))]\n",
    "\n",
    "        clf_probs = clf.predict_proba(X_test_split)\n",
    "        #Positive values only\n",
    "        clf_probs = clf_probs[:, 1]\n",
    "\n",
    "        y_predict = clf.predict(X_test_split)\n",
    "        \n",
    "        #This would be important for plotting the curve. \n",
    "        ns_precision, ns_recall,_ = precision_recall_curve(y_test_split, no_skill_probs)\n",
    "        clf_precision, clf_recall,_ = precision_recall_curve(y_test_split, clf_probs)\n",
    "\n",
    "        ns_f1, ns_auc = f1_score(y_test_split, no_skill_probs), auc(ns_recall, ns_precision)\n",
    "        clf_f1, clf_auc = f1_score(y_test_split, y_predict), auc(clf_recall, clf_precision )\n",
    "        scores_auc.append(clf_auc)\n",
    "#         output_ns = ' No skill: f1 = %3f auc = 3%f' % (ns_f1, ns_auc)\n",
    "#         output_clf = ' skill: f1 = %3f auc = 3%f' % (clf_f1, clf_auc)\n",
    "#         score_string = score_string + output_ns + output_clf\n",
    "\n",
    "#         plt.plot(clf_precision, clf_recall)\n",
    "\n",
    "#         scores = cross_val_score(clf, X_train, y_train, scoring = 'f1', cv=5)\n",
    "    \n",
    "    #Append to score string ->put in file\n",
    "    score_dict[score_string] = {'data':[np.mean(scores), np.std(scores)], 'classifier': clf}\n",
    "    score_string = score_string + 'f1 accuracy (original): %.3f +/- %.3f' % (np.mean(scores), np.std(scores)) \n",
    "    score_string = score_string + 'acc:  %.3f +/- %.3f' % (np.mean(scores_acc), np.std(scores_acc)) \n",
    "    score_string = score_string + 'auc:  %.3f +/- %.3f' % (np.mean(scores_auc), np.std(scores_auc)) \n",
    "    \n",
    "    \n",
    "    scores_file.write(score_string + '\\n')\n",
    "    scores = []\n",
    "    scores_acc = []\n",
    "    scores_auc = []\n",
    "\n",
    "    \n",
    "    #If confusion matrix is needed also include this into ouptut file. \n",
    "    if(include_confusion):\n",
    "        #Create confusion matrix\n",
    "        X_test = pd.get_dummies(X_test)\n",
    "        predictions = clf.predict(X_test)\n",
    "        print(classification_report(y_test,predictions))\n",
    "        scores_file.write(classification_report(y_test,predictions) + '\\n')\n",
    "    return score_dict\n",
    "    #     De plot werkt somehow niet\n",
    "#     # Plot learning curves\n",
    "#     title = \"Learning Curves (\" + type(clf).__name__ + ')'\n",
    "#     cv = 10\n",
    "\n",
    "#     plt = plot_learning_curve(clf, title, X_train, \n",
    "#                         y_train, ylim=(0.6, 1.01), cv=cv, n_jobs=1);\n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "prob_map = {'AD': 1, 'Other': 0}\n",
    "y_train.Indication = y_train.Indication.map(prob_map)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "classifier.fit(X_train, y_train)\n",
    "classifier.predict_proba(X_test)[:,1]\n",
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train different datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use normalizer when recoding!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "single_normal\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Run different datasets/classifiers and save output. \n",
    "\n",
    "#Output file of scores.\n",
    "scores_file = open(path+ '/Scores/test1.txt', 'w')\n",
    "\n",
    "#Train and calculate accuracy different datsets\n",
    "dict_data = {\n",
    "#     'single_mc_datedif': pat_single_mc_datedif,\n",
    "#              'single_mc_datedifcat':pat_single_mc_datedifcat, \n",
    "             'single_normal': pat_single_normal, \n",
    "#              'pat_eczemia_keep':patients_with_eczemia_keep_much,\n",
    "#              'pat_eczemia_mc': patients_with_eczemia_mc,\n",
    "#              'pat_eczemia':patients_with_eczemia_normal\n",
    "            }\n",
    "score_dict = {}\n",
    "for (key,df) in (dict_data.items()):\n",
    "    print(key)\n",
    "    print()\n",
    "    scores_file.write(key + '\\n')\n",
    "    \n",
    "    #Find object columns and make these categorical (not waterproof, numeric columns might be categorical as well)\n",
    "    categorical_columns_unordered = df.select_dtypes(include = object).columns\n",
    "    for col in categorical_columns_unordered:\n",
    "        df.loc[:,col] = pd.Categorical(df.loc[:,col], ordered = False)\n",
    "   \n",
    "    clf_dict = {\n",
    "#         'logreg_balanced': LogisticRegression(C=1,max_iter = 1000, class_weight = 'balanced', random_state= 42),\n",
    "#            'RF_balanced' :  RandomForestClassifier(random_state=42,class_weight = 'balanced', max_depth = 9),\n",
    "#             'logreg_weight': LogisticRegression(C=1,max_iter = 1000, class_weight = {'AD': 3,  'Other':1}, random_state= 42),\n",
    "#            'RF_weight' :  RandomForestClassifier(random_state=42,class_weight = {'AD': 3,  'Other':1}, max_depth = 9),\n",
    "                'logreg': LogisticRegression(random_state= 42),\n",
    "           'RF' :  RandomForestClassifier(random_state=42)  \n",
    "          }\n",
    "    \n",
    "    #Run clf_dict for different methods (also possible to run different datasets by adding a loop.)\n",
    "    for (classifier_name, clf) in (clf_dict.items()):\n",
    "        for oversample in [0,1,2]:\n",
    "            score_dict = classifier_method(df, key, clf, classifier_name, scores_file, oversample, False, score_dict)\n",
    "scores_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print all values met accuracy groter dan 0.78\n",
    "\n",
    "* Datedif cat lijkt niet een goede dataset\n",
    "* Datedif mc is lichtelijk beste. \n",
    "* Oversample voor RF doet het goed"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Prints all values in score_dict`\n",
    "for key, value in enumerate(score_dict):\n",
    "    if(score_dict[value]['data'][0] > 0.78):\n",
    "        print(value + \" \" + str(score_dict[value]['data'][0]) )\n",
    "#         print(score_dict[value]['classifier'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FIX SMOTE, EN FIX patient DING EN wERK AAN VERsLAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 42"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## Base Case Model\n",
    "logreg = LogisticRegression(C=1, class_weight = {'AD': 1, 'PsO':1, 'Other':1}, max_iter = 1000, random_state= random_state)\n",
    "logreg.fit(X_train, y_train)\n",
    "scores = cross_val_score(logreg, X_train, y_train, cv=5)\n",
    "print('CV accuracy (original): %.3f +/- %.3f' % (np.mean(scores), np.std(scores)))\n",
    "highest_score = np.mean(scores)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Plot learning curves\n",
    "title = \"Learning Curves (Logistic Regression)\"\n",
    "cv = 10\n",
    "plot_learning_curve(logreg, title, X_train, \n",
    "                    y_train, ylim=(0.6, 1.01), cv=cv, n_jobs=1);"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "predictions = logreg.predict(X_test)\n",
    "print(classification_report(y_test,predictions, target_names=logreg.classes_))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## RF Base Case\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## Base Case Model\n",
    "RF = RandomForestClassifier(random_state=random_state, max_depth = 9)\n",
    "RF.fit(X_train, y_train)\n",
    "scores = cross_val_score(RF, X_train, y_train, cv=5)\n",
    "print('CV accuracy (original): %.3f +/- %.3f' % (np.mean(scores), np.std(scores)))\n",
    "highest_score = np.mean(scores)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Plot learning curves\n",
    "title = \"Learning Curves (Logistic Regression)\"\n",
    "cv = 10\n",
    "plot_learning_curve(RF, title, X_train, \n",
    "                    y_train, ylim=(0.6, 1.01), cv=cv, n_jobs=1);"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "predictions = logreg.predict(X_test)\n",
    "print(classification_report(y_test,predictions, target_names=RF.classes_))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "nrows = ncols = 2\n",
    "fig, axes = plt.subplots(nrows = nrows, ncols = ncols, sharex=\"all\", figsize=(15,15))\n",
    "\n",
    "# names_classifiers = [(\"AdaBoosting\", ada_best),(\"ExtraTrees\",ExtC_best),(\"RandomForest\",RFC_best),(\"XGradientBoosting\",xgb_best)]\n",
    "names_classifiers = [('Random Forest', RF)]\n",
    "nclassifier = 0\n",
    "for row in range(nrows):\n",
    "    for col in range(ncols):\n",
    "        name = names_classifiers[nclassifier][0]\n",
    "        classifier = names_classifiers[nclassifier][1]\n",
    "        indices = np.argsort(classifier.feature_importances_)[::-1][:40]\n",
    "        g = sns.barplot(y=X_train.columns[indices][:40],x = classifier.feature_importances_[indices][:40] , orient='h',ax=axes[row][col])\n",
    "        g.set_xlabel(\"Relative importance\",fontsize=12)\n",
    "        g.set_ylabel(\"Features\",fontsize=12)\n",
    "        g.tick_params(labelsize=9)\n",
    "        g.set_title(name + \" feature importance\")\n",
    "        nclassifier += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ** Test more models **"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Method that splits data with over/undersampling. Not really necesarry anymore.\n",
    "#df = dataframe\n",
    "#oversample = boolean whether to oversample or not\n",
    "#Undersample = boolean whether to undersample or not (better to do this with numerical value or sth)\n",
    "def dataset_model_ready(df, oversample, undersample):\n",
    "    \n",
    "    y = df[['Indication']].reset_index(drop = True)\n",
    "    X = (df.drop(['Indication'], axis = 1)).reset_index(drop = True)\n",
    "    \n",
    "    #Save columns and datatypes (used for SMOTE)\n",
    "    columns = X.columns\n",
    "    data_types = X.dtypes\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "#     print(y_train.Indication.value_counts())\n",
    "\n",
    "    if(oversample):\n",
    "        #Fro SMOTENC you need index of categorical columns\n",
    "        cat_col_index = [X_train.columns.get_loc(c) for c in X_train.select_dtypes(include = 'category').columns if c in X_train]\n",
    "        smote_nc = SMOTENC(categorical_features=cat_col_index, random_state=42)\n",
    "        \n",
    "        X_train, y_train = smote_nc.fit_resample(X_train, y_train)\n",
    "        \n",
    "        #Create good df (Smote fucks it up)\n",
    "        X_train = pd.DataFrame(X_train)\n",
    "        X_train.columns = columns\n",
    "        X_train = X_train.astype(data_types)\n",
    "        \n",
    "        #Get dummies\n",
    "        y_train = pd.Series(y_train)\n",
    "    if(undersample):\n",
    "        no_AD = len(y_train[y_train.Indication == 'AD'])\n",
    "        \n",
    "        Other_indices = y_train[y_train.Indication== 'Other'].index\n",
    "        \n",
    "        random_indices = np.random.choice(Other_indices, no_AD, replace = False)\n",
    "        \n",
    "        AD_indices = y_train[y_train.Indication == 'AD'].index\n",
    "        under_sample_indices = np.concatenate([random_indices, AD_indices])\n",
    "\n",
    "        y_train = y_train.loc[under_sample_indices]\n",
    "        X_train = X_train.loc[under_sample_indices]\n",
    "        \n",
    "    X_train = pd.get_dummies(X_train)\n",
    "    X_test = pd.get_dummies(X_test)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "X_train, X_test, y_train, y_test = dataset_model_ready(pat_single_normal, oversample =False, undersample = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross validate model with Kfold stratified cross val\n",
    "kfold = StratifiedKFold(n_splits=3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run classifier with cross-validation and plot ROC curves\n",
    "#Some method from internet that plots ROC curve\n",
    "def cross_val_AUC(cv, classifier, X, y):\n",
    "    tprs = []\n",
    "    aucs = []\n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "    i = 0\n",
    "    for train, test in cv.split(X, y):\n",
    "        probas_ = classifier.fit(X[train], y[train]).predict_proba(X[test])\n",
    "        # Compute ROC curve and area the curve\n",
    "        fpr, tpr, thresholds = roc_curve(y[test], probas_[:, 1])\n",
    "        tprs.append(interp(mean_fpr, fpr, tpr))\n",
    "        tprs[-1][0] = 0.0\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        aucs.append(roc_auc)\n",
    "        plt.plot(fpr, tpr, lw=1, alpha=0.3,\n",
    "                 label='ROC fold %d (AUC = %0.2f)' % (i, roc_auc))\n",
    "\n",
    "        i += 1\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',\n",
    "             label='Chance', alpha=.8)\n",
    "\n",
    "    mean_tpr = np.mean(tprs, axis=0)\n",
    "    mean_tpr[-1] = 1.0\n",
    "    mean_auc = auc(mean_fpr, mean_tpr)\n",
    "    std_auc = np.std(aucs)\n",
    "    plt.plot(mean_fpr, mean_tpr, color='b',\n",
    "             label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc),\n",
    "             lw=2, alpha=.8)\n",
    "\n",
    "    std_tpr = np.std(tprs, axis=0)\n",
    "    tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "    tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "    plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2,\n",
    "                     label=r'$\\pm$ 1 std. dev.')\n",
    "\n",
    "    plt.xlim([-0.05, 1.05])\n",
    "    plt.ylim([-0.05, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic example')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "    return mean_auc, std_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run Classifier and use right cross validation to get right auc/acc/f1 score\n",
    "#df = dataframe\n",
    "#clf = classifier\n",
    "#sample_strat, whether to oversample or not. sample_strat = 0, normal, sample_strat = 1, oversample sample strat = 2 undersapmle\n",
    "def get_3_scores_method(df, clf, sample_strat):\n",
    "    \n",
    "    y = df[['Indication']]\n",
    "    \n",
    "    #Map indication from to 1's and 0's\n",
    "    binary_map = {'AD': 1, 'Other': 0}\n",
    "    y.Indication = y.Indication.map(binary_map)\n",
    "\n",
    "    X = (df.drop(['Indication'], axis = 1))\n",
    "    \n",
    "    #For SMOTE\n",
    "    columns = X.columns\n",
    "    data_types = X.dtypes\n",
    "    \n",
    "    #Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "#     print(y_train.Indication.value_counts())\n",
    "    \n",
    "    #Reset index for manual resampling\n",
    "    X_train.reset_index(inplace = True,drop = True)\n",
    "    y_train.reset_index(inplace = True, drop = True)\n",
    "    \n",
    "    #Create stratified split indices\n",
    "    skf = StratifiedKFold(n_splits = 3, random_state = 42)\n",
    "    \n",
    "    scores_f1 = []\n",
    "    scores_acc = []\n",
    "    scores_auc = []\n",
    "    \n",
    "    #Loop for every split\n",
    "    for train_index, test_index in skf.split(X_train, y_train):\n",
    "        #Make the split(of the train data!)\n",
    "        X_train_split, X_test_split = X_train.loc[train_index], X_train.loc[test_index]\n",
    "        y_train_split, y_test_split = y_train.loc[train_index], y_train.loc[test_index]\n",
    "        \n",
    "        #Oversampling\n",
    "        if(sample_strat == 1):\n",
    "            #Find categorical columns\n",
    "            cat_col_index = [X_train_split.columns.get_loc(c) for c in X_train_split.select_dtypes(include = 'category').columns if c in X_train_split]\n",
    "            \n",
    "            #OVersample X_train_split, y_train split data\n",
    "            smote_nc = SMOTENC(categorical_features=cat_col_index, random_state=42)\n",
    "            X_train_split, y_train_split = smote_nc.fit_resample(X_train_split, y_train_split)\n",
    "             \n",
    "            #Create good df (Smote fucks it up)\n",
    "            X_train_split = pd.DataFrame(X_train_split)\n",
    "            X_train_split.columns = columns\n",
    "            X_train_split = X_train_split.astype(data_types)\n",
    "            y_train_split = pd.Series(y_train_split)\n",
    "        if(sample_strat == 2):\n",
    "            no_AD = len(y_train_split[y_train_split.Indication == 1])\n",
    "\n",
    "            Other_indices = y_train_split[y_train_split.Indication== 0].index\n",
    "\n",
    "            random_indices = np.random.choice(Other_indices, no_AD, replace = True)\n",
    "\n",
    "            AD_indices = y_train_split[y_train_split.Indication == 1].index\n",
    "            under_sample_indices = np.concatenate([random_indices, AD_indices])\n",
    "\n",
    "            y_train_split = y_train_split.loc[under_sample_indices]\n",
    "            X_train_split = X_train_split.loc[under_sample_indices]\n",
    "    \n",
    "        #Get dummies\n",
    "        X_train_split = pd.get_dummies(X_train_split)\n",
    "        X_test_split = pd.get_dummies(X_test_split)\n",
    "           \n",
    "        random_state = 42\n",
    "\n",
    "        ## Base Case Model\n",
    "        clf.fit(X_train_split, y_train_split)\n",
    "        \n",
    "        y_predict = clf.predict(X_test_split)\n",
    "        scores_f1.append(f1_score(y_test_split, y_predict))\n",
    "        scores_acc.append(accuracy_score(y_test_split, y_predict))\n",
    "\n",
    "        #Add some funky auc precision recall curve\n",
    "        no_skill_probs = [0 for _ in range(len(y_test_split))]\n",
    "\n",
    "        clf_probs = clf.predict_proba(X_test_split)\n",
    "        #Positive values only\n",
    "        clf_probs = clf_probs[:, 1]\n",
    "\n",
    "        y_predict = clf.predict(X_test_split)\n",
    "\n",
    "        ns_precision, ns_recall,_ = precision_recall_curve(y_test_split, no_skill_probs)\n",
    "        clf_precision, clf_recall,_ = precision_recall_curve(y_test_split, clf_probs)\n",
    "\n",
    "        ns_f1, ns_auc = f1_score(y_test_split, no_skill_probs), auc(ns_recall, ns_precision)\n",
    "        clf_f1, clf_auc = f1_score(y_test_split, y_predict), auc(clf_recall, clf_precision )\n",
    "        scores_auc.append(clf_auc)\n",
    "#         output_ns = ' No skill: f1 = %3f auc = 3%f' % (ns_f1, ns_auc)\n",
    "#         output_clf = ' skill: f1 = %3f auc = 3%f' % (clf_f1, clf_auc)\n",
    "#         score_string = score_string + output_ns + output_clf\n",
    "\n",
    "#         plt.plot(clf_precision, clf_recall)\n",
    "\n",
    "    return scores_acc, scores_f1, scores_auc\n",
    "    #     De plot werkt somehow niet\n",
    "#     # Plot learning curves\n",
    "#     title = \"Learning Curves (\" + type(clf).__name__ + ')'\n",
    "#     cv = 10\n",
    "\n",
    "#     plt = plot_learning_curve(clf, title, X_train, \n",
    "#                         y_train, ylim=(0.6, 1.01), cv=cv, n_jobs=1);\n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Modeling step Test differents algorithms \n",
    "\n",
    "#List with all classifiers\n",
    "random_state = 2\n",
    "classifiers = []\n",
    "classifiers.append(SVC(random_state=random_state, probability = True))\n",
    "classifiers.append(DecisionTreeClassifier(random_state=random_state))\n",
    "classifiers.append(AdaBoostClassifier(DecisionTreeClassifier(random_state=random_state),random_state=random_state))\n",
    "classifiers.append(RandomForestClassifier(random_state=random_state))\n",
    "classifiers.append(ExtraTreesClassifier(random_state=random_state))\n",
    "classifiers.append(GradientBoostingClassifier(random_state=random_state))\n",
    "classifiers.append(MLPClassifier(random_state=random_state))\n",
    "classifiers.append(KNeighborsClassifier())\n",
    "classifiers.append(LogisticRegression(random_state = random_state))\n",
    "classifiers.append(LinearDiscriminantAnalysis())\n",
    "classifiers.append(XGBClassifier(random_state = random_state))\n",
    "\n",
    "cv_results = []\n",
    "cv_auc_results = []\n",
    "cv_f1_results = []\n",
    "\n",
    "for classifier in classifiers :\n",
    "    #Use get_3_scores_method which manually does cross_validation. Seems that this can be done easier with imblearn pipeline. \n",
    "    #Have to check that out. \n",
    "    \n",
    "    cv_acc, cv_f1, cv_auc = get_3_scores_method( pat_single_normal,classifier, 1)\n",
    "    cv_results.append(cv_acc)\n",
    "    cv_auc_results.append(cv_auc)\n",
    "    cv_f1_results.append(cv_f1)\n",
    "#     cv_results.append(cross_val_score(classifier, X_train, y = y_train, scoring = \"accuracy\", cv = kfold, n_jobs=4))\n",
    "#     cv_auc_results.append(cross_val_score(classifier, X_train, y = y_train, scoring = \"roc_auc\", cv = kfold, n_jobs=4))\n",
    "    \n",
    "cv_means = []\n",
    "cv_std = []\n",
    "auc_means = []\n",
    "auc_std = []\n",
    "f1_means = []\n",
    "f1_std = []\n",
    "for cv_result in cv_results:\n",
    "    cv_means.append(np.mean(cv_result))\n",
    "    cv_std.append(np.std(cv_result))\n",
    "for auc_results in cv_auc_results:\n",
    "    auc_means.append(np.mean(auc_results))\n",
    "    auc_std.append(np.std(auc_results))\n",
    "for f1_result in cv_f1_results:\n",
    "    f1_means.append(np.mean(f1_result))\n",
    "    f1_std.append(np.std(f1_result))\n",
    "\n",
    "#Create dataframe of output scores for each model\n",
    "cv_res = pd.DataFrame({\"CrossValMeans\":cv_means,\"CrossValerrors\": cv_std,'CrossVallAUC':auc_means, 'CrossVallAUCError':auc_std,  \n",
    "                       \"CrossValF1\":f1_means, \"CrossValF1Error\": f1_std, \"MeanScore\":np.divide(np.add(f1_means, auc_means),2),\n",
    "                       \"Algorithm\":[\"SVC\",\"DecisionTree\",\"AdaBoost\",\"RandomForest\",\"ExtraTrees\",\n",
    "                                    \"GradientBoosting\",\"MultipleLayerPerceptron\",\"KNeighboors\",\n",
    "                                    \"LogisticRegression\",\"LinearDiscriminantAnalysis\", \"XGBClassifier\"]})\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "LR = RandomForestClassifier(random_state = random_state)\n",
    "\n",
    "LR.fit(X_train, y_train)\n",
    "predictions = LR.predict(X_test)\n",
    "print(classification_report(y_test,predictions, target_names=LR.classes_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CrossValMeans</th>\n",
       "      <th>CrossValerrors</th>\n",
       "      <th>CrossVallAUC</th>\n",
       "      <th>CrossVallAUCError</th>\n",
       "      <th>CrossValF1</th>\n",
       "      <th>CrossValF1Error</th>\n",
       "      <th>MeanScore</th>\n",
       "      <th>Algorithm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.759139</td>\n",
       "      <td>0.020669</td>\n",
       "      <td>0.507108</td>\n",
       "      <td>0.019255</td>\n",
       "      <td>0.532812</td>\n",
       "      <td>0.022637</td>\n",
       "      <td>0.519960</td>\n",
       "      <td>LogisticRegression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.755739</td>\n",
       "      <td>0.013726</td>\n",
       "      <td>0.460757</td>\n",
       "      <td>0.012862</td>\n",
       "      <td>0.516677</td>\n",
       "      <td>0.004428</td>\n",
       "      <td>0.488717</td>\n",
       "      <td>LinearDiscriminantAnalysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.783727</td>\n",
       "      <td>0.014256</td>\n",
       "      <td>0.490523</td>\n",
       "      <td>0.032299</td>\n",
       "      <td>0.504680</td>\n",
       "      <td>0.023132</td>\n",
       "      <td>0.497602</td>\n",
       "      <td>MultipleLayerPerceptron</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.788379</td>\n",
       "      <td>0.006126</td>\n",
       "      <td>0.517674</td>\n",
       "      <td>0.004602</td>\n",
       "      <td>0.500513</td>\n",
       "      <td>0.029701</td>\n",
       "      <td>0.509093</td>\n",
       "      <td>XGBClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.783299</td>\n",
       "      <td>0.012947</td>\n",
       "      <td>0.497559</td>\n",
       "      <td>0.009331</td>\n",
       "      <td>0.484212</td>\n",
       "      <td>0.025440</td>\n",
       "      <td>0.490885</td>\n",
       "      <td>GradientBoosting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.778211</td>\n",
       "      <td>0.009215</td>\n",
       "      <td>0.470499</td>\n",
       "      <td>0.010186</td>\n",
       "      <td>0.440022</td>\n",
       "      <td>0.027371</td>\n",
       "      <td>0.455260</td>\n",
       "      <td>ExtraTrees</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.776502</td>\n",
       "      <td>0.012449</td>\n",
       "      <td>0.461104</td>\n",
       "      <td>0.046379</td>\n",
       "      <td>0.439868</td>\n",
       "      <td>0.054661</td>\n",
       "      <td>0.450486</td>\n",
       "      <td>RandomForest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.739620</td>\n",
       "      <td>0.009828</td>\n",
       "      <td>0.496262</td>\n",
       "      <td>0.003767</td>\n",
       "      <td>0.435441</td>\n",
       "      <td>0.004723</td>\n",
       "      <td>0.465852</td>\n",
       "      <td>DecisionTree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.729866</td>\n",
       "      <td>0.011760</td>\n",
       "      <td>0.482797</td>\n",
       "      <td>0.005046</td>\n",
       "      <td>0.420207</td>\n",
       "      <td>0.005653</td>\n",
       "      <td>0.451502</td>\n",
       "      <td>AdaBoost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.611518</td>\n",
       "      <td>0.017879</td>\n",
       "      <td>0.354657</td>\n",
       "      <td>0.042059</td>\n",
       "      <td>0.368435</td>\n",
       "      <td>0.039212</td>\n",
       "      <td>0.361546</td>\n",
       "      <td>KNeighboors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.689131</td>\n",
       "      <td>0.016356</td>\n",
       "      <td>0.317543</td>\n",
       "      <td>0.024078</td>\n",
       "      <td>0.348850</td>\n",
       "      <td>0.035307</td>\n",
       "      <td>0.333197</td>\n",
       "      <td>SVC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    CrossValMeans  CrossValerrors  CrossVallAUC  CrossVallAUCError  \\\n",
       "8        0.759139        0.020669      0.507108           0.019255   \n",
       "9        0.755739        0.013726      0.460757           0.012862   \n",
       "6        0.783727        0.014256      0.490523           0.032299   \n",
       "10       0.788379        0.006126      0.517674           0.004602   \n",
       "5        0.783299        0.012947      0.497559           0.009331   \n",
       "4        0.778211        0.009215      0.470499           0.010186   \n",
       "3        0.776502        0.012449      0.461104           0.046379   \n",
       "1        0.739620        0.009828      0.496262           0.003767   \n",
       "2        0.729866        0.011760      0.482797           0.005046   \n",
       "7        0.611518        0.017879      0.354657           0.042059   \n",
       "0        0.689131        0.016356      0.317543           0.024078   \n",
       "\n",
       "    CrossValF1  CrossValF1Error  MeanScore                   Algorithm  \n",
       "8     0.532812         0.022637   0.519960          LogisticRegression  \n",
       "9     0.516677         0.004428   0.488717  LinearDiscriminantAnalysis  \n",
       "6     0.504680         0.023132   0.497602     MultipleLayerPerceptron  \n",
       "10    0.500513         0.029701   0.509093               XGBClassifier  \n",
       "5     0.484212         0.025440   0.490885            GradientBoosting  \n",
       "4     0.440022         0.027371   0.455260                  ExtraTrees  \n",
       "3     0.439868         0.054661   0.450486                RandomForest  \n",
       "1     0.435441         0.004723   0.465852                DecisionTree  \n",
       "2     0.420207         0.005653   0.451502                    AdaBoost  \n",
       "7     0.368435         0.039212   0.361546                 KNeighboors  \n",
       "0     0.348850         0.035307   0.333197                         SVC  "
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot classifiers, print scores and save to output file\n",
    "cv_res = cv_res.sort_values(by = 'CrossValF1', ascending = False)\n",
    "g = sns.barplot(\"CrossValMeans\",\"Algorithm\",data = cv_res, palette=\"Set3\",orient = \"h\",**{'xerr':cv_std})\n",
    "g.set_xlabel(\"Mean Accuracy\")\n",
    "g = g.set_title(\"Cross validation scores\")\n",
    "cv_res.to_csv(path + '/Scores/test2.csv', index = False)\n",
    "cv_res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "### META MODELING  WITH ADABOOST, RF, EXTRATREES and GRADIENTBOOSTING\n",
    "\n",
    "\n",
    "# Adaboost\n",
    "ADA = AdaBoostClassifier(DecisionTreeClassifier(), random_state=7)\n",
    "ada_param_grid = {\"clf__base_estimator__criterion\" : [\"gini\", \"entropy\"],\n",
    "              \"clf__base_estimator__splitter\" :   [\"best\", \"random\"],\n",
    "              \"clf__algorithm\" : [\"SAMME\",\"SAMME.R\"],\n",
    "              \"clf__n_estimators\" :[50, 100],\n",
    "              \"clf__learning_rate\":  [0.0001, 0.001, 0.01, 0.1, 0.2, 0.3]}\n",
    "# RFC Parameters tunning \n",
    "RFC = RandomForestClassifier()\n",
    "## Search grid for optimal parameters\n",
    "rf_param_grid = {\"clf__max_depth\": [2, 5, 10, 50],\n",
    "              \"clf__max_features\": [1, 3, 10, 30],\n",
    "              \"clf__min_samples_split\": [2, 3, 10],\n",
    "              \"clf__min_samples_leaf\": [1, 3, 10],\n",
    "              \"clf__bootstrap\": [True, False],\n",
    "              \"clf__n_estimators\" :[50, 100,300],\n",
    "              \"clf__criterion\": [\"gini\"], \n",
    "                'clf__random_state': [42]}\n",
    "#ExtraTrees \n",
    "EXT = ExtraTreesClassifier()\n",
    "## Search grid for optimal parameters\n",
    "ex_param_grid = {\"clf__max_depth\": [2,5,10,50],\n",
    "              \"clf__max_features\": [1, 3, 10],\n",
    "              \"clf__min_samples_split\": [2, 3, 10],\n",
    "              \"clf__min_samples_leaf\": [1, 3, 10],\n",
    "              \"clf__bootstrap\": [True, False],\n",
    "              \"clf__n_estimators\" :[100,300],\n",
    "              \"clf__criterion\": [\"gini\"]}\n",
    "#XGB\n",
    "'''\n",
    "#brute force scan for all parameters, here are the tricks\n",
    "#usually max_depth is 6,7,8\n",
    "#learning rate is around 0.05, but small changes may make big diff\n",
    "#tuning min_child_weight subsample colsample_bytree can have \n",
    "#much fun of fighting against overfit \n",
    "#n_estimators is how many round of boosting\n",
    "#finally, ensemble xgboost with multiple seeds may reduce variance\n",
    "xgb_param_grid = {'nthread':[4], #when use hyperthread, xgboost may become slower\n",
    "              'objective':['binary:logistic'],\n",
    "              'learning_rate': [0.05], #so called `eta` value\n",
    "              'max_depth': [6],\n",
    "              'min_child_weight': [11],\n",
    "              'silent': [1],\n",
    "              'subsample': [0.8],\n",
    "              'colsample_bytree': [0.7],\n",
    "              'n_estimators': [5], #number of trees, change it to 1000 for better results\n",
    "              'missing':[-999],\n",
    "              'seed': [1337]}\n",
    "'''\n",
    "XGB = xgb.XGBClassifier()\n",
    "# A parameter grid for XGBoost\n",
    "xgb_param_grid = {\n",
    "        'clf__eta': [0.0001, 0.001, 0.01, 0.1, 0.2, 0.3],\n",
    "#         'clf__min_child_weight': [1, 5, 10],\n",
    "        'clf__gamma': [0.5, 1.5, 2, 5],\n",
    "        'clf__subsample': [0.6, 0.8, 1],\n",
    "        'clf__colsample_bytree': [0.6, 0.8, 1.0],\n",
    "        'clf__max_depth': [2, 5, 10, 50]\n",
    "        }\n",
    "#GBC\n",
    "GBC = GradientBoostingClassifier(random_state = 42)\n",
    "gbc_param_grid = {'clf__learning_rate':[0.0001, 0.001, 0.01, 0.1, 0.2, 0.3],\n",
    "                 \"clf__max_features\": [1, 3, 10, 30],\n",
    "              \"clf__min_samples_split\": [2, 3, 10],\n",
    "              \"clf__min_samples_leaf\": [1, 3, 10],\n",
    "                  \"clf__n_estimators\" : [50,100, 300], \n",
    "                 \"clf__max_depth\" : [2,5,10,50],\n",
    "                 }\n",
    "\n",
    "#LogReg\n",
    "LR = LogisticRegression(random_state = 42)\n",
    "lr_param_grid = {\n",
    "    'clf__C': [0.0001, 0.001, 0.01, 0.1, 0.5, 1],\n",
    "                'clf__penalty': ['l1', 'l2']\n",
    "}\n",
    "#MLP\n",
    "MLP = MLPClassifier(random_state=random_state)\n",
    "mlp_param_grid = {\"clf__activation\" : ['identity', 'logistic', 'tanh', 'relu'], \n",
    "                 'clf__alpha':  [0.0001, 0.001, 0.01, 0.1, 0.5, 1]}\n",
    "\n",
    "#LDA\n",
    "LDA = LinearDiscriminantAnalysis()\n",
    "lda_param_grid = {}\n",
    "\n",
    "\n",
    "# #w/ oversample\n",
    "# meta_dict = {{'xgb': {'clf' :XGB, 'grid' : xgb_param_grid},}\n",
    "#             'gbc': {'clf'  : GBC, 'grid' : gbc_param_grid},\n",
    "#             'extra': {'clf' : EXT, 'grid' : ex_param_grid},\n",
    "#             'RF': {'clf' :RFC, 'grid' : rf_param_grid}\n",
    "#             }\n",
    "# # w oversample\n",
    "# meta_dict = {'xgb': {'clf' :XGB, 'grid' : xgb_param_grid},\n",
    "#             'logreg':{'clf':LR,'grid':lr_param_grid},\n",
    "#             'mlp': {'clf': MLP, 'grid':mlp_param_grid},\n",
    "#             'LDA':{'clf':LDA,'grid':lda_param_grid}}\n",
    "#w/ undersample\n",
    "meta_dict = {\n",
    "            'gbc': {'clf'  : GBC, 'grid' : gbc_param_grid},\n",
    "            'xgb': {'clf' :XGB, 'grid' : xgb_param_grid},\n",
    "    \n",
    "            'logreg': {'clf' : LR, 'grid' : lr_param_grid},\n",
    "            'RF': {'clf' :RFC, 'grid' : rf_param_grid}\n",
    "            }\n",
    "# meta_dict = {\n",
    "#             'gbc': {'clf'  : GBC, 'grid' : gbc_param_grid},\n",
    "#             'xgb': {'clf' :XGB, 'grid' : xgb_param_grid},\n",
    "    \n",
    "#             'Extra': {'clf' : EXT, 'grid' : ex_param_grid},\n",
    "#             'RF': {'clf' :RFC, 'grid' : rf_param_grid}\n",
    "    \n",
    "# }"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "### META MODELING  WITH ADABOOST, RF, EXTRATREES and GRADIENTBOOSTING\n",
    "# Cross validate model with Kfold stratified cross val\n",
    "kfold = StratifiedKFold(n_splits=5)\n",
    "\n",
    "# Adaboost\n",
    "ADA = AdaBoostClassifier(DecisionTreeClassifier(), random_state=7)\n",
    "ada_param_grid = {\"base_estimator__criterion\" : [\"gini\"],\n",
    "              \"base_estimator__splitter\" :   [\"best\"],\n",
    "              \"algorithm\" : [\"SAMME\"],\n",
    "              \"n_estimators\" :[50],\n",
    "              \"learning_rate\":  [ 0.3]}\n",
    "# RFC Parameters tunning \n",
    "RFC = RandomForestClassifier()\n",
    "## Search grid for optimal parameters\n",
    "rf_param_grid = {\"max_depth\": [None],\n",
    "              \"max_features\": [1],\n",
    "              \"min_samples_split\": [2],\n",
    "              \"min_samples_leaf\": [1],\n",
    "              \"bootstrap\": [False],\n",
    "              \"n_estimators\" :[100],\n",
    "              \"criterion\": [\"gini\"]}\n",
    "#ExtraTrees \n",
    "EXT = ExtraTreesClassifier()\n",
    "## Search grid for optimal parameters\n",
    "ex_param_grid = {\"max_depth\": [None],\n",
    "              \"max_features\": [1],\n",
    "              \"min_samples_split\": [2],\n",
    "              \"min_samples_leaf\": [1],\n",
    "              \"bootstrap\": [False],\n",
    "              \"n_estimators\" :[100],\n",
    "              \"criterion\": [\"gini\"]}\n",
    "#XGB\n",
    "'''\n",
    "#brute force scan for all parameters, here are the tricks\n",
    "#usually max_depth is 6,7,8\n",
    "#learning rate is around 0.05, but small changes may make big diff\n",
    "#tuning min_child_weight subsample colsample_bytree can have \n",
    "#much fun of fighting against overfit \n",
    "#n_estimators is how many round of boosting\n",
    "#finally, ensemble xgboost with multiple seeds may reduce variance\n",
    "xgb_param_grid = {'nthread':[4], #when use hyperthread, xgboost may become slower\n",
    "              'objective':['binary:logistic'],\n",
    "              'learning_rate': [0.05], #so called `eta` value\n",
    "              'max_depth': [6],\n",
    "              'min_child_weight': [11],\n",
    "              'silent': [1],\n",
    "              'subsample': [0.8],\n",
    "              'colsample_bytree': [0.7],\n",
    "              'n_estimators': [5], #number of trees, change it to 1000 for better results\n",
    "              'missing':[-999],\n",
    "              'seed': [1337]}\n",
    "'''\n",
    "XGB = xgb.XGBClassifier()\n",
    "# A parameter grid for XGBoost\n",
    "xgb_param_grid = {\n",
    "        'min_child_weight': [1],\n",
    "        'gamma': [0.5],\n",
    "        'subsample': [0.60],\n",
    "        'colsample_bytree': [0.60],\n",
    "        'max_depth': [3]\n",
    "        }\n",
    "#GBC\n",
    "GBC = GradientBoostingClassifier(random_state = 42)\n",
    "gbc_param_grid = {'learning_rate':[0.0001],\n",
    "                 \"max_features\": [1],\n",
    "              \"min_samples_split\": [ 10],\n",
    "              \"min_samples_leaf\": [ 10],\n",
    "                  \"n_estimators\" : [100], \n",
    "                 \"max_depth\" : [7],\n",
    "                 }\n",
    "meta_dict = {'xgb': {'clf' :XGB, 'grid' : xgb_param_grid},\n",
    "            'gbc': {'clf'  : GBC, 'grid' : gbc_param_grid},\n",
    "            'extra': {'clf' : EXT, 'grid' : ex_param_grid},\n",
    "            'RF': {'clf' :RFC, 'grid' : rf_param_grid}\n",
    "            }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Method that creates voting classifier and saves output to file\n",
    "#best_dict = dictionary with methods that have been finetuned and are taken up in voting classifier\n",
    "#file = file to which data will be saved\n",
    "def create_voting_clf_and_output(best_dict, file):\n",
    "    best_clf_list = [(k,v) for k,v in best_dict.items()]\n",
    "    \n",
    "    #Prints individual scores of models\n",
    "    for clf_name,clf in best_clf_list:\n",
    "        y_predict = clf.predict(X_test)\n",
    "        file.write(clf_name + \" has f1 score of: \" + str(f1_score(y_test, y_predict)) + '\\n' )\n",
    "        file.write(clf_name + \" has accuracy score of: \" + str(accuracy_score(y_test, y_predict)) + '\\n' )\n",
    "    \n",
    "    #Creates voting classifier\n",
    "    voting_clf = VotingClassifier(estimators=best_clf_list, voting='soft', n_jobs=4)\n",
    "    voting_clf.fit(X_train,y_train)\n",
    "    \n",
    "    #Prints scores to output file (thought that confusion matrix didn't work)\n",
    "    predictions = voting_clf.predict(X_test)\n",
    "    file.write(classification_report(y_test,predictions) + '\\n')\n",
    "#     file.write(confusion_matrix(y_test.Indication, predictions) + '\\n')\n",
    "   \n",
    "    roc_scores = cross_val_score(voting_clf, X_test, y = y_test, scoring = \"roc_auc\", cv = kfold, n_jobs=-1)\n",
    "    file.write('ROC_AUC score: ' + str(roc_scores.mean()) +'\\n')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "best_clf_list = [(k,v) for k,v in best_clf_RGS_dict.items()]\n",
    "voting_clf = VotingClassifier(estimators=best_clf_list, voting='soft', n_jobs=4)\n",
    "voting_clf.fit(X_train, y_train)\n",
    "y_predict = voting_clf.predict(X_test)\n",
    "confusion_matrix(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier\n",
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   12.1s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   34.8s\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:   50.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier\n",
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   13.2s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  1.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression\n",
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  36 out of  36 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier\n",
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   17.6s\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:   28.6s finished\n"
     ]
    }
   ],
   "source": [
    "#File to which output is saved\n",
    "search_file = \\\n",
    "    open(path + '/Scores/test3.txt', 'w')\n",
    "\n",
    "# Cross validate model with Kfold stratified cross val\n",
    "y = df[['Indication']]\n",
    "prob_map = {'AD': 1, 'Other': 0}  \n",
    "y.Indication = y.Indication.map(prob_map)\n",
    "X = (df.drop(['Indication'], axis = 1))\n",
    "\n",
    "#Splits data(this can be done somewhere in start of code actually)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "kfold = StratifiedKFold(n_splits = 3, random_state = 42)\n",
    "\n",
    "#Get dummies\n",
    "X_train = pd.get_dummies(X_train)\n",
    "X_test = pd.get_dummies(X_test)\n",
    "\n",
    "#Make matrix because otherwise rus does not work\n",
    "X_train = X_train.as_matrix()\n",
    "X_test = X_test.as_matrix()\n",
    "\n",
    "best_clf_GS_dict = {}\n",
    "best_clf_RGS_dict = {}\n",
    "\n",
    "# starttimeGS = datetime.datetime.now()\n",
    "# for i, k in enumerate(meta_dict):\n",
    "#     clf = meta_dict[k]['clf']\n",
    "#     grid = meta_dict[k]['grid']\n",
    "#     clfGridSearch = GridSearchCV(clf,param_grid = grid, cv=kfold, scoring=\"accuracy\", n_jobs= -1, verbose = 1)\n",
    "#     clfGridSearch.fit(X_train, y_train)\n",
    "#     best_clf_GS_dict[k] = clfGridSearch.best_estimator_\n",
    "# endtimeGS= datetime.datetime.now()\n",
    "# delta_time = endtimeGS - starttimeGS\n",
    "# search_file.write('Grid search took: ' + str(delta_time) + \" ms \\n\")\n",
    "\n",
    "# create_voting_clf_and_output(best_clf_GS_dict, search_file)\n",
    "\n",
    "starttimeRS = datetime.datetime.now()\n",
    "for i, k in enumerate(meta_dict):\n",
    "    #Get classifier and param grid from meta dictionary\n",
    "    clf = meta_dict[k]['clf']\n",
    "    grid = meta_dict[k]['grid']\n",
    "    \n",
    "    #Use IMBLEARN Pipeline (in that case resampling will be done on kfold training data)\n",
    "    model = Pipeline([('sampling', RandomUnderSampler(random_state = 42)),\n",
    "                     ('clf', clf)])\n",
    "#     model = Pipeline([('sampling', SMOTE(random_state=42)),\n",
    "#                      ('clf', clf)])\n",
    "    clfGridSearch = RandomizedSearchCV(model,param_distributions= grid, cv=kfold,n_iter = 100, scoring=\"f1\", n_jobs= -1, verbose = 1, random_state = 42)\n",
    "    print(type(clf).__name__)\n",
    "    #Fit the gridsearch\n",
    "    clfGridSearch.fit(X_train,y_train)\n",
    "    \n",
    "    #Save best estimator to dict\n",
    "    best_clf_RGS_dict[k] = clfGridSearch.best_estimator_\n",
    "endtimeRS= datetime.datetime.now()\n",
    "#Computes total running time (used to compare RGS with GS)\n",
    "delta_time = endtimeRS - starttimeRS\n",
    "search_file.write('Random search took: ' + str(delta_time) + \" ms \\n\")\n",
    "\n",
    "#Create voting classifier\n",
    "create_voting_clf_and_output(best_clf_RGS_dict, search_file)\n",
    "\n",
    "search_file.close()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "best_clf_RGS_dict"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    " best_clf_list = [(k,v) for k,v in best_clf_GS_dict.items()]\n",
    "best_clf_RGS_dict['xgb'].fit(X_train,y_train)\n",
    "#  voting_clf = VotingClassifier(estimators=best_clf_list, voting='soft', n_jobs=4)\n",
    "#     voting_clf.fit(X_train,y_train)\n",
    "print(classification_report(y_train,best_clf_RGS_dict['extra'].predict(X_train), target_names=best_clf_RGS_dict['xgb'].classes_))\n",
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
